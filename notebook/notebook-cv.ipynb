{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "from model import get_model\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config seed for reproducible codes\n",
    "SEED = 17167055\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "def loader(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return Image.open(f).convert(\"RGB\")\n",
    "\n",
    "\n",
    "# stratified sampling\n",
    "def stratified(df, col, n_smaples):\n",
    "    n = min(n_smaples, df[col].value_counts().min())\n",
    "    df_ = df.groupby(col).apply(lambda x: x.sample(n))\n",
    "    df_.index = df_.index.droplevel(0)\n",
    "    return df_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../data/preprocess/\")\n",
    "data = [str(i) for i in list(path.glob(\"*.jpg\"))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"filename\"] = [i.split(\"\\\\\")[-1] for i in data]\n",
    "df[\"pixels\"] = [loader(i) for i in data]\n",
    "df[\"label\"] = [int(i[0]) for i in df[\"filename\"]]\n",
    "df[\"id\"] = [\"-\".join(i.split(\"_\")[1:-2]) for i in df[\"filename\"]]\n",
    "df[\"var\"] = [i.split(\".\")[0][-1] for i in df[\"filename\"]]\n",
    "df[\"ga\"] = [i.split(\"_\")[-2] for i in df[\"filename\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all duplicates to make dataset more clean\n",
    "df = df[df[\"var\"] == \"0\"].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>pixels</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>var</th>\n",
       "      <th>ga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_057_21-5_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>0</td>\n",
       "      <td>057</td>\n",
       "      <td>0</td>\n",
       "      <td>21-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_080_21-3_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>0</td>\n",
       "      <td>080</td>\n",
       "      <td>0</td>\n",
       "      <td>21-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_082_21-6_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>0</td>\n",
       "      <td>082</td>\n",
       "      <td>0</td>\n",
       "      <td>21-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_087_21-2_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>0</td>\n",
       "      <td>087</td>\n",
       "      <td>0</td>\n",
       "      <td>21-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_096_21-6_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>0</td>\n",
       "      <td>096</td>\n",
       "      <td>0</td>\n",
       "      <td>21-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1_JessTay-Sample8_21-4_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>1</td>\n",
       "      <td>JessTay-Sample8</td>\n",
       "      <td>0</td>\n",
       "      <td>21-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1_May-IUGR2_21-3_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>1</td>\n",
       "      <td>May-IUGR2</td>\n",
       "      <td>0</td>\n",
       "      <td>21-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1_May-IUGR4_22-0_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>1</td>\n",
       "      <td>May-IUGR4</td>\n",
       "      <td>0</td>\n",
       "      <td>22-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1_SN-Sample12_IUGR3_22-4_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>1</td>\n",
       "      <td>SN-Sample12-IUGR3</td>\n",
       "      <td>0</td>\n",
       "      <td>22-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1_SN-stiff-I3_21-0_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>1</td>\n",
       "      <td>SN-stiff-I3</td>\n",
       "      <td>0</td>\n",
       "      <td>21-0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filename  \\\n",
       "0                 0_057_21-5_0.jpg   \n",
       "1                 0_080_21-3_0.jpg   \n",
       "2                 0_082_21-6_0.jpg   \n",
       "3                 0_087_21-2_0.jpg   \n",
       "4                 0_096_21-6_0.jpg   \n",
       "..                             ...   \n",
       "85    1_JessTay-Sample8_21-4_0.jpg   \n",
       "86          1_May-IUGR2_21-3_0.jpg   \n",
       "87          1_May-IUGR4_22-0_0.jpg   \n",
       "88  1_SN-Sample12_IUGR3_22-4_0.jpg   \n",
       "89        1_SN-stiff-I3_21-0_0.jpg   \n",
       "\n",
       "                                               pixels  label  \\\n",
       "0   <PIL.Image.Image image mode=RGB size=448x112 a...      0   \n",
       "1   <PIL.Image.Image image mode=RGB size=448x112 a...      0   \n",
       "2   <PIL.Image.Image image mode=RGB size=448x112 a...      0   \n",
       "3   <PIL.Image.Image image mode=RGB size=448x112 a...      0   \n",
       "4   <PIL.Image.Image image mode=RGB size=448x112 a...      0   \n",
       "..                                                ...    ...   \n",
       "85  <PIL.Image.Image image mode=RGB size=448x112 a...      1   \n",
       "86  <PIL.Image.Image image mode=RGB size=448x112 a...      1   \n",
       "87  <PIL.Image.Image image mode=RGB size=448x112 a...      1   \n",
       "88  <PIL.Image.Image image mode=RGB size=448x112 a...      1   \n",
       "89  <PIL.Image.Image image mode=RGB size=448x112 a...      1   \n",
       "\n",
       "                   id var    ga  \n",
       "0                 057   0  21-5  \n",
       "1                 080   0  21-3  \n",
       "2                 082   0  21-6  \n",
       "3                 087   0  21-2  \n",
       "4                 096   0  21-6  \n",
       "..                ...  ..   ...  \n",
       "85    JessTay-Sample8   0  21-4  \n",
       "86          May-IUGR2   0  21-3  \n",
       "87          May-IUGR4   0  22-0  \n",
       "88  SN-Sample12-IUGR3   0  22-4  \n",
       "89        SN-stiff-I3   0  21-0  \n",
       "\n",
       "[90 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicated = df[df.duplicated(\"id\", keep=False)]\n",
    "df_unique = df.drop(df_duplicated.index)\n",
    "df_duplicated = df_duplicated.reset_index(drop=True)\n",
    "df_unique = df_unique.reset_index(drop=True)\n",
    "\n",
    "# test set\n",
    "df_test = stratified(df_unique, \"label\", 5)\n",
    "df_unique = df_unique.drop(df_test.index).reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv = pd.concat([df_duplicated, df_unique], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>pixels</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>var</th>\n",
       "      <th>ga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_JessTay-Sample3_20-0_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>0</td>\n",
       "      <td>JessTay-Sample3</td>\n",
       "      <td>0</td>\n",
       "      <td>20-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_JessTay-Sample3_23-2_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>0</td>\n",
       "      <td>JessTay-Sample3</td>\n",
       "      <td>0</td>\n",
       "      <td>23-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_057_21-5_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>0</td>\n",
       "      <td>057</td>\n",
       "      <td>0</td>\n",
       "      <td>21-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_082_21-6_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>0</td>\n",
       "      <td>082</td>\n",
       "      <td>0</td>\n",
       "      <td>21-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_087_21-2_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>0</td>\n",
       "      <td>087</td>\n",
       "      <td>0</td>\n",
       "      <td>21-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1_JessTay-Sample8_21-4_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>1</td>\n",
       "      <td>JessTay-Sample8</td>\n",
       "      <td>0</td>\n",
       "      <td>21-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1_May-IUGR2_21-3_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>1</td>\n",
       "      <td>May-IUGR2</td>\n",
       "      <td>0</td>\n",
       "      <td>21-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1_May-IUGR4_22-0_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>1</td>\n",
       "      <td>May-IUGR4</td>\n",
       "      <td>0</td>\n",
       "      <td>22-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1_SN-Sample12_IUGR3_22-4_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>1</td>\n",
       "      <td>SN-Sample12-IUGR3</td>\n",
       "      <td>0</td>\n",
       "      <td>22-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1_SN-stiff-I3_21-0_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>1</td>\n",
       "      <td>SN-stiff-I3</td>\n",
       "      <td>0</td>\n",
       "      <td>21-0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filename  \\\n",
       "0     0_JessTay-Sample3_20-0_0.jpg   \n",
       "1     0_JessTay-Sample3_23-2_0.jpg   \n",
       "2                 0_057_21-5_0.jpg   \n",
       "3                 0_082_21-6_0.jpg   \n",
       "4                 0_087_21-2_0.jpg   \n",
       "..                             ...   \n",
       "75    1_JessTay-Sample8_21-4_0.jpg   \n",
       "76          1_May-IUGR2_21-3_0.jpg   \n",
       "77          1_May-IUGR4_22-0_0.jpg   \n",
       "78  1_SN-Sample12_IUGR3_22-4_0.jpg   \n",
       "79        1_SN-stiff-I3_21-0_0.jpg   \n",
       "\n",
       "                                               pixels  label  \\\n",
       "0   <PIL.Image.Image image mode=RGB size=448x112 a...      0   \n",
       "1   <PIL.Image.Image image mode=RGB size=448x112 a...      0   \n",
       "2   <PIL.Image.Image image mode=RGB size=448x112 a...      0   \n",
       "3   <PIL.Image.Image image mode=RGB size=448x112 a...      0   \n",
       "4   <PIL.Image.Image image mode=RGB size=448x112 a...      0   \n",
       "..                                                ...    ...   \n",
       "75  <PIL.Image.Image image mode=RGB size=448x112 a...      1   \n",
       "76  <PIL.Image.Image image mode=RGB size=448x112 a...      1   \n",
       "77  <PIL.Image.Image image mode=RGB size=448x112 a...      1   \n",
       "78  <PIL.Image.Image image mode=RGB size=448x112 a...      1   \n",
       "79  <PIL.Image.Image image mode=RGB size=448x112 a...      1   \n",
       "\n",
       "                   id var    ga  \n",
       "0     JessTay-Sample3   0  20-0  \n",
       "1     JessTay-Sample3   0  23-2  \n",
       "2                 057   0  21-5  \n",
       "3                 082   0  21-6  \n",
       "4                 087   0  21-2  \n",
       "..                ...  ..   ...  \n",
       "75    JessTay-Sample8   0  21-4  \n",
       "76          May-IUGR2   0  21-3  \n",
       "77          May-IUGR4   0  22-0  \n",
       "78  SN-Sample12-IUGR3   0  22-4  \n",
       "79        SN-stiff-I3   0  21-0  \n",
       "\n",
       "[80 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>pixels</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>var</th>\n",
       "      <th>ga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_172_22-0_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>22-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_May-N8_21-4_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>0</td>\n",
       "      <td>May-N8</td>\n",
       "      <td>0</td>\n",
       "      <td>21-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_143_22-1_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>22-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_JessLow-N6_22-2_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>0</td>\n",
       "      <td>JessLow-N6</td>\n",
       "      <td>0</td>\n",
       "      <td>22-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_080_21-3_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>0</td>\n",
       "      <td>080</td>\n",
       "      <td>0</td>\n",
       "      <td>21-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1_169_22-1_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>22-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1_161_21-0_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>21-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1_177_22-3_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>1</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>22-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1_188_S3_28-5_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>1</td>\n",
       "      <td>188-S3</td>\n",
       "      <td>0</td>\n",
       "      <td>28-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1_JessTay-Sample6_22-5_0.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=448x112 a...</td>\n",
       "      <td>1</td>\n",
       "      <td>JessTay-Sample6</td>\n",
       "      <td>0</td>\n",
       "      <td>22-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       filename  \\\n",
       "0              0_172_22-0_0.jpg   \n",
       "1           0_May-N8_21-4_0.jpg   \n",
       "2              0_143_22-1_0.jpg   \n",
       "3       0_JessLow-N6_22-2_0.jpg   \n",
       "4              0_080_21-3_0.jpg   \n",
       "5              1_169_22-1_0.jpg   \n",
       "6              1_161_21-0_0.jpg   \n",
       "7              1_177_22-3_0.jpg   \n",
       "8           1_188_S3_28-5_0.jpg   \n",
       "9  1_JessTay-Sample6_22-5_0.jpg   \n",
       "\n",
       "                                              pixels  label               id  \\\n",
       "0  <PIL.Image.Image image mode=RGB size=448x112 a...      0              172   \n",
       "1  <PIL.Image.Image image mode=RGB size=448x112 a...      0           May-N8   \n",
       "2  <PIL.Image.Image image mode=RGB size=448x112 a...      0              143   \n",
       "3  <PIL.Image.Image image mode=RGB size=448x112 a...      0       JessLow-N6   \n",
       "4  <PIL.Image.Image image mode=RGB size=448x112 a...      0              080   \n",
       "5  <PIL.Image.Image image mode=RGB size=448x112 a...      1              169   \n",
       "6  <PIL.Image.Image image mode=RGB size=448x112 a...      1              161   \n",
       "7  <PIL.Image.Image image mode=RGB size=448x112 a...      1              177   \n",
       "8  <PIL.Image.Image image mode=RGB size=448x112 a...      1           188-S3   \n",
       "9  <PIL.Image.Image image mode=RGB size=448x112 a...      1  JessTay-Sample6   \n",
       "\n",
       "  var    ga  \n",
       "0   0  22-0  \n",
       "1   0  21-4  \n",
       "2   0  22-1  \n",
       "3   0  22-2  \n",
       "4   0  21-3  \n",
       "5   0  22-1  \n",
       "6   0  21-0  \n",
       "7   0  22-3  \n",
       "8   0  28-5  \n",
       "9   0  22-5  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scv = StratifiedKFold(n_splits=8, shuffle=True, random_state=SEED)\n",
    "x_cv = df_cv.drop(columns=[\"label\"])\n",
    "y_cv = df_cv[\"label\"]\n",
    "cv_set = {\n",
    "    \"train\": [],\n",
    "    \"val\": [],\n",
    "}\n",
    "for idx, (train_index, val_index) in enumerate(scv.split(x_cv, y_cv)):\n",
    "    # print(f\"Split {idx}\")\n",
    "    # print(f\"Total train: {len(train_index)}\")\n",
    "    # print(f\"Total val: {len(val_index)}\")\n",
    "    cv_set[\"train\"].append(df_cv.loc[train_index])\n",
    "    cv_set[\"val\"].append(df_cv.loc[val_index])\n",
    "    # print(\"Val label:\", cv_set[\"val\"][idx][\"label\"].tolist())\n",
    "    # print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "    \"train\": A.Compose(\n",
    "        [\n",
    "            A.CLAHE(p=0.8),\n",
    "            A.RandomCrop(112, 112),\n",
    "            A.Normalize(\n",
    "                mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0], max_pixel_value=255.0\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    ),\n",
    "    \"test\": A.Compose(\n",
    "        [\n",
    "            A.Normalize(\n",
    "                mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0], max_pixel_value=255.0\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DopplerDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.img = self.df[\"pixels\"]\n",
    "        self.lbl = self.df[\"label\"]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img[idx]\n",
    "        lbl = self.lbl[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(image=np.array(img))[\"image\"]\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, loader, net, model_name, split):\n",
    "    net.train()\n",
    "    totalLoss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(loader, desc=f\"Training split {split} {model_name}: {epoch+1}/{n_epoch}\")\n",
    "    for X, y in pbar:\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        out = net(X)\n",
    "        y = y.unsqueeze(dim=1).float()\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        totalLoss += loss.item()\n",
    "        pred = (torch.sigmoid(out) > 0.5).float()\n",
    "        total += y.size(0)\n",
    "        correct += pred.eq(y).cpu().sum()\n",
    "        pbar.set_postfix({\"loss\": (totalLoss), \"acc\": (100.0 * correct / total).item()})\n",
    "    acc = (100.0 * correct / total).item()\n",
    "    return acc, totalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_val(epoch, loader, net, model_name, split):\n",
    "    net.eval()\n",
    "    totalLoss = 0\n",
    "    correct = 0\n",
    "    total = 2\n",
    "    pbar = tqdm(loader, desc=f\"Evaluating split {split} {model_name}: {epoch+1}/{n_epoch}\")\n",
    "    with torch.no_grad():\n",
    "        for X, y in pbar:\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "            out = net(X)\n",
    "            y = y.unsqueeze(dim=1).float()\n",
    "            loss = criterion(out, y)\n",
    "            totalLoss += loss.item()\n",
    "            pred = (torch.sigmoid(out) > 0.5).float()\n",
    "            # total += y.size(0)\n",
    "            weight = 1/val_counts[1] if y.item()==1 else 1/val_counts[0]\n",
    "            correct += pred.eq(y).cpu().sum()*weight\n",
    "            pbar.set_postfix(\n",
    "                {\"loss\": (totalLoss), \"acc\": (100.0 * correct / total).item()}\n",
    "            )\n",
    "    acc = (100.0 * correct / total).item()\n",
    "    return acc, totalLoss\n",
    "\n",
    "def evaluate_test(epoch, loader, net, model_name, split):\n",
    "    net.eval()\n",
    "    totalLoss = 0\n",
    "    correct = 0\n",
    "    total = 2\n",
    "    pbar = tqdm(loader, desc=f\"Evaluating split {split} {model_name}: {epoch+1}/{n_epoch}\")\n",
    "    with torch.no_grad():\n",
    "        for X, y in pbar:\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "            out = net(X)\n",
    "            y = y.unsqueeze(dim=1).float()\n",
    "            loss = criterion(out, y)\n",
    "            totalLoss += loss.item()\n",
    "            pred = (torch.sigmoid(out) > 0.5).float()\n",
    "            # total += y.size(0)\n",
    "            weight = 1/test_counts[1] if y.item()==1 else 1/test_counts[0]\n",
    "            correct += pred.eq(y).cpu().sum()*weight\n",
    "            pbar.set_postfix(\n",
    "                {\"loss\": (totalLoss), \"acc\": (100.0 * correct / total).item()}\n",
    "            )\n",
    "    acc = (100.0 * correct / total).item()\n",
    "    return acc, totalLoss\n",
    "\n",
    "# def evaluate_test(epoch, loader, net, model_name, split):\n",
    "#     net.eval()\n",
    "#     totalLoss = 0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     pbar = tqdm(loader, desc=f\"Evaluating split {split} {model_name}: {epoch+1}/{n_epoch}\")\n",
    "#     with torch.no_grad():\n",
    "#         for X, y in pbar:\n",
    "#             X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "#             out = net(X)\n",
    "#             y = y.unsqueeze(dim=1).float()\n",
    "#             loss = criterion(out, y)\n",
    "#             totalLoss += loss.item()\n",
    "#             pred = (torch.sigmoid(out) > 0.5).float()\n",
    "#             total += y.size(0)\n",
    "#             correct += pred.eq(y).cpu().sum()\n",
    "#             pbar.set_postfix(\n",
    "#                 {\"loss\": (totalLoss), \"acc\": (100.0 * correct / total).item()}\n",
    "#             )\n",
    "#     acc = (100.0 * correct / total).item()\n",
    "#     return acc, totalLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0 0 0 1 1]\n",
    "weight of 0 is 1/3\n",
    "weight of 1 is 1/2\n",
    "total weight = 2+3=5\n",
    "[0 0 0 0 1]\n",
    "acc = 1.5/2=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = DopplerDataset(df_test, transform=transform[\"test\"])\n",
    "testLoader = DataLoader(testset, batch_size=1, shuffle=False)\n",
    "test_counts = df_test[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training split 0 densenet121-pretrained-adam: 1/25: 100%|██████████| 5/5 [00:04<00:00,  1.21it/s, loss=3.55, acc=58.6]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 1/25: 100%|██████████| 10/10 [00:00<00:00, 25.83it/s, loss=6.43, acc=44.4]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 1/25: 100%|██████████| 10/10 [00:00<00:00, 27.82it/s, loss=6.89, acc=70]\n",
      "Training split 0 densenet121-pretrained-adam: 2/25: 100%|██████████| 5/5 [00:00<00:00,  6.01it/s, loss=3.28, acc=64.3]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 2/25: 100%|██████████| 10/10 [00:00<00:00, 28.08it/s, loss=6.45, acc=33.3]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 2/25: 100%|██████████| 10/10 [00:00<00:00, 25.18it/s, loss=6.4, acc=70]\n",
      "Training split 0 densenet121-pretrained-adam: 3/25: 100%|██████████| 5/5 [00:00<00:00,  5.21it/s, loss=3.1, acc=64.3]  \n",
      "Evaluating split 0 densenet121-pretrained-adam: 3/25: 100%|██████████| 10/10 [00:00<00:00, 26.45it/s, loss=6.76, acc=83.3]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 3/25: 100%|██████████| 10/10 [00:00<00:00, 23.58it/s, loss=6.13, acc=80]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val 83.33333587646484, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training split 0 densenet121-pretrained-adam: 4/25: 100%|██████████| 5/5 [00:00<00:00,  5.73it/s, loss=2.73, acc=72.9]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 4/25: 100%|██████████| 10/10 [00:00<00:00, 26.04it/s, loss=7, acc=22.2]  \n",
      "Evaluating split 0 densenet121-pretrained-adam: 4/25: 100%|██████████| 10/10 [00:00<00:00, 25.25it/s, loss=5.9, acc=80]\n",
      "Training split 0 densenet121-pretrained-adam: 5/25: 100%|██████████| 5/5 [00:00<00:00,  5.99it/s, loss=2.75, acc=74.3] \n",
      "Evaluating split 0 densenet121-pretrained-adam: 5/25: 100%|██████████| 10/10 [00:00<00:00, 26.52it/s, loss=6.8, acc=33.3]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 5/25: 100%|██████████| 10/10 [00:00<00:00, 25.97it/s, loss=5.81, acc=80]\n",
      "Training split 0 densenet121-pretrained-adam: 6/25: 100%|██████████| 5/5 [00:00<00:00,  5.92it/s, loss=2.31, acc=75.7]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 6/25: 100%|██████████| 10/10 [00:00<00:00, 25.50it/s, loss=6.34, acc=38.9]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 6/25: 100%|██████████| 10/10 [00:00<00:00, 25.18it/s, loss=6.04, acc=70]\n",
      "Training split 0 densenet121-pretrained-adam: 7/25: 100%|██████████| 5/5 [00:00<00:00,  5.54it/s, loss=2.35, acc=87.1] \n",
      "Evaluating split 0 densenet121-pretrained-adam: 7/25: 100%|██████████| 10/10 [00:00<00:00, 25.90it/s, loss=6.2, acc=38.9]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 7/25: 100%|██████████| 10/10 [00:00<00:00, 26.04it/s, loss=6.65, acc=60]\n",
      "Training split 0 densenet121-pretrained-adam: 8/25: 100%|██████████| 5/5 [00:00<00:00,  5.94it/s, loss=2.47, acc=75.7]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 8/25: 100%|██████████| 10/10 [00:00<00:00, 26.59it/s, loss=6.75, acc=27.8]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 8/25: 100%|██████████| 10/10 [00:00<00:00, 25.70it/s, loss=6.51, acc=80]\n",
      "Training split 0 densenet121-pretrained-adam: 9/25: 100%|██████████| 5/5 [00:00<00:00,  5.82it/s, loss=2.36, acc=81.4] \n",
      "Evaluating split 0 densenet121-pretrained-adam: 9/25: 100%|██████████| 10/10 [00:00<00:00, 25.77it/s, loss=7.59, acc=27.8]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 9/25: 100%|██████████| 10/10 [00:00<00:00, 24.93it/s, loss=6.41, acc=70]\n",
      "Training split 0 densenet121-pretrained-adam: 10/25: 100%|██████████| 5/5 [00:00<00:00,  5.64it/s, loss=2.1, acc=85.7] \n",
      "Evaluating split 0 densenet121-pretrained-adam: 10/25: 100%|██████████| 10/10 [00:00<00:00, 25.57it/s, loss=8.03, acc=22.2]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 10/25: 100%|██████████| 10/10 [00:00<00:00, 25.31it/s, loss=6.17, acc=70]\n",
      "Training split 0 densenet121-pretrained-adam: 11/25: 100%|██████████| 5/5 [00:00<00:00,  5.62it/s, loss=2.09, acc=85.7] \n",
      "Evaluating split 0 densenet121-pretrained-adam: 11/25: 100%|██████████| 10/10 [00:00<00:00, 25.77it/s, loss=7.73, acc=22.2]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 11/25: 100%|██████████| 10/10 [00:00<00:00, 26.66it/s, loss=6.42, acc=60]\n",
      "Training split 0 densenet121-pretrained-adam: 12/25: 100%|██████████| 5/5 [00:00<00:00,  5.97it/s, loss=1.6, acc=85.7]  \n",
      "Evaluating split 0 densenet121-pretrained-adam: 12/25: 100%|██████████| 10/10 [00:00<00:00, 25.12it/s, loss=8.04, acc=22.2]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 12/25: 100%|██████████| 10/10 [00:00<00:00, 28.32it/s, loss=6.32, acc=60]\n",
      "Training split 0 densenet121-pretrained-adam: 13/25: 100%|██████████| 5/5 [00:00<00:00,  5.67it/s, loss=2, acc=91.4]    \n",
      "Evaluating split 0 densenet121-pretrained-adam: 13/25: 100%|██████████| 10/10 [00:00<00:00, 26.80it/s, loss=8.1, acc=27.8]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 13/25: 100%|██████████| 10/10 [00:00<00:00, 26.73it/s, loss=6.1, acc=50]\n",
      "Training split 0 densenet121-pretrained-adam: 14/25: 100%|██████████| 5/5 [00:00<00:00,  5.55it/s, loss=1.59, acc=91.4] \n",
      "Evaluating split 0 densenet121-pretrained-adam: 14/25: 100%|██████████| 10/10 [00:00<00:00, 26.24it/s, loss=8.16, acc=27.8]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 14/25: 100%|██████████| 10/10 [00:00<00:00, 26.59it/s, loss=6.31, acc=60]\n",
      "Training split 0 densenet121-pretrained-adam: 15/25: 100%|██████████| 5/5 [00:00<00:00,  5.81it/s, loss=1.8, acc=87.1]  \n",
      "Evaluating split 0 densenet121-pretrained-adam: 15/25: 100%|██████████| 10/10 [00:00<00:00, 27.24it/s, loss=7.16, acc=27.8]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 15/25: 100%|██████████| 10/10 [00:00<00:00, 26.73it/s, loss=6.72, acc=70]\n",
      "Training split 0 densenet121-pretrained-adam: 16/25: 100%|██████████| 5/5 [00:00<00:00,  5.60it/s, loss=1.53, acc=91.4] \n",
      "Evaluating split 0 densenet121-pretrained-adam: 16/25: 100%|██████████| 10/10 [00:00<00:00, 26.31it/s, loss=6.7, acc=27.8]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 16/25: 100%|██████████| 10/10 [00:00<00:00, 26.73it/s, loss=6.75, acc=70]\n",
      "Training split 0 densenet121-pretrained-adam: 17/25: 100%|██████████| 5/5 [00:00<00:00,  5.75it/s, loss=2.04, acc=91.4] \n",
      "Evaluating split 0 densenet121-pretrained-adam: 17/25: 100%|██████████| 10/10 [00:00<00:00, 25.97it/s, loss=5.8, acc=38.9]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 17/25: 100%|██████████| 10/10 [00:00<00:00, 25.64it/s, loss=6.72, acc=70]\n",
      "Training split 0 densenet121-pretrained-adam: 18/25: 100%|██████████| 5/5 [00:00<00:00,  6.07it/s, loss=1.81, acc=88.6] \n",
      "Evaluating split 0 densenet121-pretrained-adam: 18/25: 100%|██████████| 10/10 [00:00<00:00, 27.17it/s, loss=5.5, acc=38.9]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 18/25: 100%|██████████| 10/10 [00:00<00:00, 28.73it/s, loss=6.92, acc=60]\n",
      "Training split 0 densenet121-pretrained-adam: 19/25: 100%|██████████| 5/5 [00:00<00:00,  5.74it/s, loss=0.911, acc=95.7]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 19/25: 100%|██████████| 10/10 [00:00<00:00, 27.17it/s, loss=6.05, acc=33.3]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 19/25: 100%|██████████| 10/10 [00:00<00:00, 26.38it/s, loss=7.2, acc=70]\n",
      "Training split 0 densenet121-pretrained-adam: 20/25: 100%|██████████| 5/5 [00:00<00:00,  5.89it/s, loss=0.894, acc=95.7]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 20/25: 100%|██████████| 10/10 [00:00<00:00, 26.80it/s, loss=5.82, acc=38.9]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 20/25: 100%|██████████| 10/10 [00:00<00:00, 26.95it/s, loss=7.48, acc=70]\n",
      "Training split 0 densenet121-pretrained-adam: 21/25: 100%|██████████| 5/5 [00:00<00:00,  5.91it/s, loss=0.914, acc=95.7]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 21/25: 100%|██████████| 10/10 [00:00<00:00, 23.64it/s, loss=5.47, acc=44.4]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 21/25: 100%|██████████| 10/10 [00:00<00:00, 25.70it/s, loss=7.58, acc=70]\n",
      "Training split 0 densenet121-pretrained-adam: 22/25: 100%|██████████| 5/5 [00:00<00:00,  5.87it/s, loss=0.733, acc=94.3]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 22/25: 100%|██████████| 10/10 [00:00<00:00, 25.97it/s, loss=6.02, acc=38.9]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 22/25: 100%|██████████| 10/10 [00:00<00:00, 26.73it/s, loss=7.06, acc=80]\n",
      "Training split 0 densenet121-pretrained-adam: 23/25: 100%|██████████| 5/5 [00:00<00:00,  5.58it/s, loss=0.995, acc=95.7]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 23/25: 100%|██████████| 10/10 [00:00<00:00, 26.45it/s, loss=7.1, acc=33.3]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 23/25: 100%|██████████| 10/10 [00:00<00:00, 26.80it/s, loss=6.89, acc=60]\n",
      "Training split 0 densenet121-pretrained-adam: 24/25: 100%|██████████| 5/5 [00:00<00:00,  5.56it/s, loss=0.603, acc=97.1]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 24/25: 100%|██████████| 10/10 [00:00<00:00, 21.59it/s, loss=7.77, acc=27.8]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 24/25: 100%|██████████| 10/10 [00:00<00:00, 23.64it/s, loss=7.38, acc=50]\n",
      "Training split 0 densenet121-pretrained-adam: 25/25: 100%|██████████| 5/5 [00:00<00:00,  5.35it/s, loss=0.745, acc=94.3]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 25/25: 100%|██████████| 10/10 [00:00<00:00, 27.32it/s, loss=7.17, acc=27.8]\n",
      "Evaluating split 0 densenet121-pretrained-adam: 25/25: 100%|██████████| 10/10 [00:00<00:00, 25.70it/s, loss=7.02, acc=50]\n",
      "Training split 1 densenet121-pretrained-adam: 1/25: 100%|██████████| 5/5 [00:01<00:00,  4.89it/s, loss=3.68, acc=57.1] \n",
      "Evaluating split 1 densenet121-pretrained-adam: 1/25: 100%|██████████| 10/10 [00:00<00:00, 25.83it/s, loss=4.9, acc=50]  \n",
      "Evaluating split 1 densenet121-pretrained-adam: 1/25: 100%|██████████| 10/10 [00:00<00:00, 25.90it/s, loss=7.53, acc=50]\n",
      "Training split 1 densenet121-pretrained-adam: 2/25: 100%|██████████| 5/5 [00:00<00:00,  5.81it/s, loss=3, acc=65.7]   \n",
      "Evaluating split 1 densenet121-pretrained-adam: 2/25: 100%|██████████| 10/10 [00:00<00:00, 25.83it/s, loss=4.7, acc=50]  \n",
      "Evaluating split 1 densenet121-pretrained-adam: 2/25: 100%|██████████| 10/10 [00:00<00:00, 25.37it/s, loss=7.25, acc=50]\n",
      "Training split 1 densenet121-pretrained-adam: 3/25: 100%|██████████| 5/5 [00:00<00:00,  6.16it/s, loss=2.92, acc=71.4] \n",
      "Evaluating split 1 densenet121-pretrained-adam: 3/25: 100%|██████████| 10/10 [00:00<00:00, 26.88it/s, loss=4.28, acc=50]  \n",
      "Evaluating split 1 densenet121-pretrained-adam: 3/25: 100%|██████████| 10/10 [00:00<00:00, 26.95it/s, loss=7.27, acc=50]\n",
      "Training split 1 densenet121-pretrained-adam: 4/25: 100%|██████████| 5/5 [00:00<00:00,  5.76it/s, loss=2.69, acc=72.9] \n",
      "Evaluating split 1 densenet121-pretrained-adam: 4/25: 100%|██████████| 10/10 [00:00<00:00, 24.62it/s, loss=4.27, acc=50]  \n",
      "Evaluating split 1 densenet121-pretrained-adam: 4/25: 100%|██████████| 10/10 [00:00<00:00, 25.83it/s, loss=7.45, acc=50]\n",
      "Training split 1 densenet121-pretrained-adam: 5/25: 100%|██████████| 5/5 [00:01<00:00,  4.72it/s, loss=2.37, acc=78.6]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 5/25: 100%|██████████| 10/10 [00:00<00:00, 26.24it/s, loss=4.36, acc=50] \n",
      "Evaluating split 1 densenet121-pretrained-adam: 5/25: 100%|██████████| 10/10 [00:00<00:00, 25.44it/s, loss=7.7, acc=50]\n",
      "Training split 1 densenet121-pretrained-adam: 6/25: 100%|██████████| 5/5 [00:00<00:00,  5.99it/s, loss=2.76, acc=71.4] \n",
      "Evaluating split 1 densenet121-pretrained-adam: 6/25: 100%|██████████| 10/10 [00:00<00:00, 25.06it/s, loss=4.34, acc=50]  \n",
      "Evaluating split 1 densenet121-pretrained-adam: 6/25: 100%|██████████| 10/10 [00:00<00:00, 24.44it/s, loss=7.82, acc=50]\n",
      "Training split 1 densenet121-pretrained-adam: 7/25: 100%|██████████| 5/5 [00:00<00:00,  5.62it/s, loss=2.19, acc=78.6] \n",
      "Evaluating split 1 densenet121-pretrained-adam: 7/25: 100%|██████████| 10/10 [00:00<00:00, 25.06it/s, loss=4.14, acc=50]  \n",
      "Evaluating split 1 densenet121-pretrained-adam: 7/25: 100%|██████████| 10/10 [00:00<00:00, 27.69it/s, loss=7.86, acc=50]\n",
      "Training split 1 densenet121-pretrained-adam: 8/25: 100%|██████████| 5/5 [00:00<00:00,  6.33it/s, loss=2.2, acc=80]    \n",
      "Evaluating split 1 densenet121-pretrained-adam: 8/25: 100%|██████████| 10/10 [00:00<00:00, 26.59it/s, loss=4.43, acc=50]  \n",
      "Evaluating split 1 densenet121-pretrained-adam: 8/25: 100%|██████████| 10/10 [00:00<00:00, 26.58it/s, loss=7.8, acc=50]\n",
      "Training split 1 densenet121-pretrained-adam: 9/25: 100%|██████████| 5/5 [00:00<00:00,  6.04it/s, loss=2.21, acc=78.6]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 9/25: 100%|██████████| 10/10 [00:00<00:00, 28.98it/s, loss=4.65, acc=50]  \n",
      "Evaluating split 1 densenet121-pretrained-adam: 9/25: 100%|██████████| 10/10 [00:00<00:00, 25.31it/s, loss=7.98, acc=50]\n",
      "Training split 1 densenet121-pretrained-adam: 10/25: 100%|██████████| 5/5 [00:00<00:00,  5.76it/s, loss=1.6, acc=94.3]  \n",
      "Evaluating split 1 densenet121-pretrained-adam: 10/25: 100%|██████████| 10/10 [00:00<00:00, 27.77it/s, loss=4.68, acc=44.4]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 10/25: 100%|██████████| 10/10 [00:00<00:00, 27.17it/s, loss=8.27, acc=50]\n",
      "Training split 1 densenet121-pretrained-adam: 11/25: 100%|██████████| 5/5 [00:00<00:00,  6.29it/s, loss=1.8, acc=85.7]  \n",
      "Evaluating split 1 densenet121-pretrained-adam: 11/25: 100%|██████████| 10/10 [00:00<00:00, 28.00it/s, loss=5.29, acc=38.9]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 11/25: 100%|██████████| 10/10 [00:00<00:00, 26.10it/s, loss=7.85, acc=50]\n",
      "Training split 1 densenet121-pretrained-adam: 12/25: 100%|██████████| 5/5 [00:00<00:00,  5.67it/s, loss=1.28, acc=90]   \n",
      "Evaluating split 1 densenet121-pretrained-adam: 12/25: 100%|██████████| 10/10 [00:00<00:00, 26.80it/s, loss=5.7, acc=38.9]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 12/25: 100%|██████████| 10/10 [00:00<00:00, 27.47it/s, loss=7.61, acc=50]\n",
      "Training split 1 densenet121-pretrained-adam: 13/25: 100%|██████████| 5/5 [00:00<00:00,  6.02it/s, loss=1.13, acc=94.3] \n",
      "Evaluating split 1 densenet121-pretrained-adam: 13/25: 100%|██████████| 10/10 [00:00<00:00, 25.83it/s, loss=6.19, acc=38.9]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 13/25: 100%|██████████| 10/10 [00:00<00:00, 26.95it/s, loss=7.33, acc=60]\n",
      "Training split 1 densenet121-pretrained-adam: 14/25: 100%|██████████| 5/5 [00:00<00:00,  5.99it/s, loss=1.26, acc=97.1] \n",
      "Evaluating split 1 densenet121-pretrained-adam: 14/25: 100%|██████████| 10/10 [00:00<00:00, 24.50it/s, loss=6.24, acc=38.9]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 14/25: 100%|██████████| 10/10 [00:00<00:00, 26.73it/s, loss=6.87, acc=50]\n",
      "Training split 1 densenet121-pretrained-adam: 15/25: 100%|██████████| 5/5 [00:00<00:00,  5.99it/s, loss=1.61, acc=91.4] \n",
      "Evaluating split 1 densenet121-pretrained-adam: 15/25: 100%|██████████| 10/10 [00:00<00:00, 25.50it/s, loss=5.98, acc=38.9]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 15/25: 100%|██████████| 10/10 [00:00<00:00, 26.16it/s, loss=6.77, acc=60]\n",
      "Training split 1 densenet121-pretrained-adam: 16/25: 100%|██████████| 5/5 [00:00<00:00,  5.54it/s, loss=1.59, acc=85.7] \n",
      "Evaluating split 1 densenet121-pretrained-adam: 16/25: 100%|██████████| 10/10 [00:00<00:00, 24.99it/s, loss=6.26, acc=38.9]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 16/25: 100%|██████████| 10/10 [00:00<00:00, 24.87it/s, loss=6.47, acc=50]\n",
      "Training split 1 densenet121-pretrained-adam: 17/25: 100%|██████████| 5/5 [00:00<00:00,  6.33it/s, loss=1.02, acc=92.9] \n",
      "Evaluating split 1 densenet121-pretrained-adam: 17/25: 100%|██████████| 10/10 [00:00<00:00, 27.85it/s, loss=6.11, acc=38.9]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 17/25: 100%|██████████| 10/10 [00:00<00:00, 26.88it/s, loss=6.09, acc=70]\n",
      "Training split 1 densenet121-pretrained-adam: 18/25: 100%|██████████| 5/5 [00:00<00:00,  5.85it/s, loss=1.26, acc=95.7] \n",
      "Evaluating split 1 densenet121-pretrained-adam: 18/25: 100%|██████████| 10/10 [00:00<00:00, 26.38it/s, loss=6.24, acc=33.3]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 18/25: 100%|██████████| 10/10 [00:00<00:00, 26.21it/s, loss=6.01, acc=70]\n",
      "Training split 1 densenet121-pretrained-adam: 19/25: 100%|██████████| 5/5 [00:00<00:00,  5.65it/s, loss=1.21, acc=88.6] \n",
      "Evaluating split 1 densenet121-pretrained-adam: 19/25: 100%|██████████| 10/10 [00:00<00:00, 25.44it/s, loss=6.09, acc=38.9]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 19/25: 100%|██████████| 10/10 [00:00<00:00, 26.45it/s, loss=5.79, acc=80]\n",
      "Training split 1 densenet121-pretrained-adam: 20/25: 100%|██████████| 5/5 [00:00<00:00,  5.71it/s, loss=0.709, acc=95.7]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 20/25: 100%|██████████| 10/10 [00:00<00:00, 27.90it/s, loss=5.94, acc=38.9]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 20/25: 100%|██████████| 10/10 [00:00<00:00, 27.02it/s, loss=6.04, acc=70]\n",
      "Training split 1 densenet121-pretrained-adam: 21/25: 100%|██████████| 5/5 [00:00<00:00,  5.61it/s, loss=0.871, acc=94.3]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 21/25: 100%|██████████| 10/10 [00:00<00:00, 26.52it/s, loss=5.91, acc=38.9]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 21/25: 100%|██████████| 10/10 [00:00<00:00, 27.47it/s, loss=6.08, acc=70]\n",
      "Training split 1 densenet121-pretrained-adam: 22/25: 100%|██████████| 5/5 [00:00<00:00,  6.01it/s, loss=0.467, acc=98.6]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 22/25: 100%|██████████| 10/10 [00:00<00:00, 23.98it/s, loss=5.88, acc=38.9]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 22/25: 100%|██████████| 10/10 [00:00<00:00, 25.06it/s, loss=6.03, acc=70]\n",
      "Training split 1 densenet121-pretrained-adam: 23/25: 100%|██████████| 5/5 [00:00<00:00,  5.33it/s, loss=0.841, acc=95.7]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 23/25: 100%|██████████| 10/10 [00:00<00:00, 26.66it/s, loss=5.96, acc=33.3]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 23/25: 100%|██████████| 10/10 [00:00<00:00, 24.87it/s, loss=5.86, acc=80]\n",
      "Training split 1 densenet121-pretrained-adam: 24/25: 100%|██████████| 5/5 [00:00<00:00,  5.75it/s, loss=1.04, acc=90]   \n",
      "Evaluating split 1 densenet121-pretrained-adam: 24/25: 100%|██████████| 10/10 [00:00<00:00, 24.44it/s, loss=6.15, acc=33.3]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 24/25: 100%|██████████| 10/10 [00:00<00:00, 23.69it/s, loss=6.26, acc=80]\n",
      "Training split 1 densenet121-pretrained-adam: 25/25: 100%|██████████| 5/5 [00:00<00:00,  5.71it/s, loss=1, acc=94.3]    \n",
      "Evaluating split 1 densenet121-pretrained-adam: 25/25: 100%|██████████| 10/10 [00:00<00:00, 26.66it/s, loss=6.13, acc=38.9]\n",
      "Evaluating split 1 densenet121-pretrained-adam: 25/25: 100%|██████████| 10/10 [00:00<00:00, 26.24it/s, loss=6.13, acc=80]\n",
      "Training split 2 densenet121-pretrained-adam: 1/25: 100%|██████████| 5/5 [00:00<00:00,  6.12it/s, loss=3.46, acc=47.1] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 1/25: 100%|██████████| 10/10 [00:00<00:00, 25.97it/s, loss=5.76, acc=50] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 1/25: 100%|██████████| 10/10 [00:00<00:00, 24.81it/s, loss=7.49, acc=50]\n",
      "Training split 2 densenet121-pretrained-adam: 2/25: 100%|██████████| 5/5 [00:00<00:00,  5.62it/s, loss=3.35, acc=51.4] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 2/25: 100%|██████████| 10/10 [00:00<00:00, 26.73it/s, loss=5.44, acc=50] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 2/25: 100%|██████████| 10/10 [00:00<00:00, 25.50it/s, loss=7.97, acc=50]\n",
      "Training split 2 densenet121-pretrained-adam: 3/25: 100%|██████████| 5/5 [00:00<00:00,  5.79it/s, loss=2.79, acc=71.4] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 3/25: 100%|██████████| 10/10 [00:00<00:00, 24.38it/s, loss=5.28, acc=50] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 3/25: 100%|██████████| 10/10 [00:00<00:00, 24.69it/s, loss=8.06, acc=50]\n",
      "Training split 2 densenet121-pretrained-adam: 4/25: 100%|██████████| 5/5 [00:00<00:00,  5.81it/s, loss=3.34, acc=64.3]\n",
      "Evaluating split 2 densenet121-pretrained-adam: 4/25: 100%|██████████| 10/10 [00:00<00:00, 26.04it/s, loss=5.22, acc=50] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 4/25: 100%|██████████| 10/10 [00:00<00:00, 24.75it/s, loss=8.04, acc=50]\n",
      "Training split 2 densenet121-pretrained-adam: 5/25: 100%|██████████| 5/5 [00:00<00:00,  6.04it/s, loss=3, acc=65.7]    \n",
      "Evaluating split 2 densenet121-pretrained-adam: 5/25: 100%|██████████| 10/10 [00:00<00:00, 26.66it/s, loss=4.87, acc=50] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 5/25: 100%|██████████| 10/10 [00:00<00:00, 25.18it/s, loss=8.3, acc=50]\n",
      "Training split 2 densenet121-pretrained-adam: 6/25: 100%|██████████| 5/5 [00:00<00:00,  5.46it/s, loss=2.55, acc=75.7] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 6/25: 100%|██████████| 10/10 [00:00<00:00, 22.62it/s, loss=4.81, acc=50] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 6/25: 100%|██████████| 10/10 [00:00<00:00, 23.98it/s, loss=7.97, acc=50]\n",
      "Training split 2 densenet121-pretrained-adam: 7/25: 100%|██████████| 5/5 [00:00<00:00,  5.45it/s, loss=2.55, acc=75.7] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 7/25: 100%|██████████| 10/10 [00:00<00:00, 24.09it/s, loss=5.02, acc=50] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 7/25: 100%|██████████| 10/10 [00:00<00:00, 23.58it/s, loss=7.67, acc=50]\n",
      "Training split 2 densenet121-pretrained-adam: 8/25: 100%|██████████| 5/5 [00:00<00:00,  5.77it/s, loss=2.32, acc=80]   \n",
      "Evaluating split 2 densenet121-pretrained-adam: 8/25: 100%|██████████| 10/10 [00:00<00:00, 26.45it/s, loss=5.26, acc=50] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 8/25: 100%|██████████| 10/10 [00:00<00:00, 25.12it/s, loss=7.3, acc=60]\n",
      "Training split 2 densenet121-pretrained-adam: 9/25: 100%|██████████| 5/5 [00:00<00:00,  5.39it/s, loss=2.24, acc=87.1] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 9/25: 100%|██████████| 10/10 [00:00<00:00, 23.47it/s, loss=5.22, acc=50] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 9/25: 100%|██████████| 10/10 [00:00<00:00, 25.83it/s, loss=6.96, acc=60]\n",
      "Training split 2 densenet121-pretrained-adam: 10/25: 100%|██████████| 5/5 [00:00<00:00,  5.44it/s, loss=2, acc=90]      \n",
      "Evaluating split 2 densenet121-pretrained-adam: 10/25: 100%|██████████| 10/10 [00:00<00:00, 25.70it/s, loss=5.44, acc=68.8]\n",
      "Evaluating split 2 densenet121-pretrained-adam: 10/25: 100%|██████████| 10/10 [00:00<00:00, 23.75it/s, loss=6.84, acc=60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val 68.75, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training split 2 densenet121-pretrained-adam: 11/25: 100%|██████████| 5/5 [00:00<00:00,  6.25it/s, loss=2.14, acc=80]   \n",
      "Evaluating split 2 densenet121-pretrained-adam: 11/25: 100%|██████████| 10/10 [00:00<00:00, 23.36it/s, loss=5.25, acc=75] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 11/25: 100%|██████████| 10/10 [00:00<00:00, 22.83it/s, loss=6.78, acc=60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val 75.0, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training split 2 densenet121-pretrained-adam: 12/25: 100%|██████████| 5/5 [00:00<00:00,  5.22it/s, loss=1.59, acc=87.1] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 12/25: 100%|██████████| 10/10 [00:00<00:00, 23.69it/s, loss=5.14, acc=100]\n",
      "Evaluating split 2 densenet121-pretrained-adam: 12/25: 100%|██████████| 10/10 [00:00<00:00, 25.64it/s, loss=6.53, acc=60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val 100.0, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training split 2 densenet121-pretrained-adam: 13/25: 100%|██████████| 5/5 [00:00<00:00,  5.63it/s, loss=1.66, acc=88.6] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 13/25: 100%|██████████| 10/10 [00:00<00:00, 25.50it/s, loss=5.04, acc=100]\n",
      "Evaluating split 2 densenet121-pretrained-adam: 13/25: 100%|██████████| 10/10 [00:00<00:00, 25.83it/s, loss=6.24, acc=60]\n",
      "Training split 2 densenet121-pretrained-adam: 14/25: 100%|██████████| 5/5 [00:00<00:00,  6.12it/s, loss=2.03, acc=77.1] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 14/25: 100%|██████████| 10/10 [00:00<00:00, 26.52it/s, loss=4.9, acc=100] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 14/25: 100%|██████████| 10/10 [00:00<00:00, 26.04it/s, loss=6.2, acc=70]\n",
      "Training split 2 densenet121-pretrained-adam: 15/25: 100%|██████████| 5/5 [00:00<00:00,  5.67it/s, loss=1.51, acc=94.3] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 15/25: 100%|██████████| 10/10 [00:00<00:00, 27.24it/s, loss=4.96, acc=100]\n",
      "Evaluating split 2 densenet121-pretrained-adam: 15/25: 100%|██████████| 10/10 [00:00<00:00, 25.57it/s, loss=6.18, acc=70]\n",
      "Training split 2 densenet121-pretrained-adam: 16/25: 100%|██████████| 5/5 [00:00<00:00,  5.40it/s, loss=1.51, acc=94.3] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 16/25: 100%|██████████| 10/10 [00:00<00:00, 26.52it/s, loss=4.6, acc=50]  \n",
      "Evaluating split 2 densenet121-pretrained-adam: 16/25: 100%|██████████| 10/10 [00:00<00:00, 26.24it/s, loss=6.42, acc=60]\n",
      "Training split 2 densenet121-pretrained-adam: 17/25: 100%|██████████| 5/5 [00:00<00:00,  5.94it/s, loss=1.6, acc=92.9]  \n",
      "Evaluating split 2 densenet121-pretrained-adam: 17/25: 100%|██████████| 10/10 [00:00<00:00, 27.69it/s, loss=4.74, acc=50] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 17/25: 100%|██████████| 10/10 [00:00<00:00, 27.17it/s, loss=5.99, acc=60]\n",
      "Training split 2 densenet121-pretrained-adam: 18/25: 100%|██████████| 5/5 [00:00<00:00,  6.00it/s, loss=1.21, acc=92.9] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 18/25: 100%|██████████| 10/10 [00:00<00:00, 27.17it/s, loss=5.01, acc=50] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 18/25: 100%|██████████| 10/10 [00:00<00:00, 27.77it/s, loss=5.81, acc=60]\n",
      "Training split 2 densenet121-pretrained-adam: 19/25: 100%|██████████| 5/5 [00:00<00:00,  6.07it/s, loss=1.08, acc=92.9] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 19/25: 100%|██████████| 10/10 [00:00<00:00, 26.10it/s, loss=5.13, acc=50] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 19/25: 100%|██████████| 10/10 [00:00<00:00, 25.77it/s, loss=5.64, acc=70]\n",
      "Training split 2 densenet121-pretrained-adam: 20/25: 100%|██████████| 5/5 [00:00<00:00,  5.99it/s, loss=0.929, acc=97.1]\n",
      "Evaluating split 2 densenet121-pretrained-adam: 20/25: 100%|██████████| 10/10 [00:00<00:00, 26.24it/s, loss=5.1, acc=43.8]\n",
      "Evaluating split 2 densenet121-pretrained-adam: 20/25: 100%|██████████| 10/10 [00:00<00:00, 26.10it/s, loss=5.68, acc=70]\n",
      "Training split 2 densenet121-pretrained-adam: 21/25: 100%|██████████| 5/5 [00:00<00:00,  5.44it/s, loss=0.916, acc=90]  \n",
      "Evaluating split 2 densenet121-pretrained-adam: 21/25: 100%|██████████| 10/10 [00:00<00:00, 23.80it/s, loss=5.18, acc=68.8]\n",
      "Evaluating split 2 densenet121-pretrained-adam: 21/25: 100%|██████████| 10/10 [00:00<00:00, 25.77it/s, loss=5.7, acc=70]\n",
      "Training split 2 densenet121-pretrained-adam: 22/25: 100%|██████████| 5/5 [00:00<00:00,  5.79it/s, loss=0.823, acc=94.3]\n",
      "Evaluating split 2 densenet121-pretrained-adam: 22/25: 100%|██████████| 10/10 [00:00<00:00, 25.77it/s, loss=5.78, acc=68.8]\n",
      "Evaluating split 2 densenet121-pretrained-adam: 22/25: 100%|██████████| 10/10 [00:00<00:00, 25.97it/s, loss=5.97, acc=70]\n",
      "Training split 2 densenet121-pretrained-adam: 23/25: 100%|██████████| 5/5 [00:00<00:00,  5.98it/s, loss=0.695, acc=95.7]\n",
      "Evaluating split 2 densenet121-pretrained-adam: 23/25: 100%|██████████| 10/10 [00:00<00:00, 24.27it/s, loss=5.57, acc=68.8]\n",
      "Evaluating split 2 densenet121-pretrained-adam: 23/25: 100%|██████████| 10/10 [00:00<00:00, 25.06it/s, loss=6, acc=60]  \n",
      "Training split 2 densenet121-pretrained-adam: 24/25: 100%|██████████| 5/5 [00:00<00:00,  5.52it/s, loss=0.619, acc=95.7]\n",
      "Evaluating split 2 densenet121-pretrained-adam: 24/25: 100%|██████████| 10/10 [00:00<00:00, 26.17it/s, loss=5.41, acc=68.8]\n",
      "Evaluating split 2 densenet121-pretrained-adam: 24/25: 100%|██████████| 10/10 [00:00<00:00, 26.17it/s, loss=6.01, acc=60]\n",
      "Training split 2 densenet121-pretrained-adam: 25/25: 100%|██████████| 5/5 [00:00<00:00,  6.20it/s, loss=0.558, acc=100] \n",
      "Evaluating split 2 densenet121-pretrained-adam: 25/25: 100%|██████████| 10/10 [00:00<00:00, 28.73it/s, loss=5.53, acc=68.8]\n",
      "Evaluating split 2 densenet121-pretrained-adam: 25/25: 100%|██████████| 10/10 [00:00<00:00, 26.10it/s, loss=6.1, acc=60] \n",
      "Training split 3 densenet121-pretrained-adam: 1/25: 100%|██████████| 5/5 [00:00<00:00,  6.11it/s, loss=3.67, acc=40]   \n",
      "Evaluating split 3 densenet121-pretrained-adam: 1/25: 100%|██████████| 10/10 [00:00<00:00, 24.36it/s, loss=7.2, acc=37.5]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 1/25: 100%|██████████| 10/10 [00:00<00:00, 25.50it/s, loss=6.8, acc=70]\n",
      "Training split 3 densenet121-pretrained-adam: 2/25: 100%|██████████| 5/5 [00:00<00:00,  5.76it/s, loss=3.41, acc=52.9] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 2/25: 100%|██████████| 10/10 [00:00<00:00, 24.15it/s, loss=6.85, acc=43.8]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 2/25: 100%|██████████| 10/10 [00:00<00:00, 25.18it/s, loss=6.27, acc=80]\n",
      "Training split 3 densenet121-pretrained-adam: 3/25: 100%|██████████| 5/5 [00:00<00:00,  6.19it/s, loss=3.5, acc=55.7] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 3/25: 100%|██████████| 10/10 [00:00<00:00, 26.73it/s, loss=6.5, acc=31.2]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 3/25: 100%|██████████| 10/10 [00:00<00:00, 24.99it/s, loss=6.42, acc=50]\n",
      "Training split 3 densenet121-pretrained-adam: 4/25: 100%|██████████| 5/5 [00:00<00:00,  5.96it/s, loss=2.71, acc=78.6]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 4/25: 100%|██████████| 10/10 [00:00<00:00, 26.66it/s, loss=6.4, acc=43.8]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 4/25: 100%|██████████| 10/10 [00:00<00:00, 24.15it/s, loss=6.82, acc=40]\n",
      "Training split 3 densenet121-pretrained-adam: 5/25: 100%|██████████| 5/5 [00:00<00:00,  6.26it/s, loss=2.68, acc=77.1]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 5/25: 100%|██████████| 10/10 [00:00<00:00, 23.36it/s, loss=6.24, acc=50] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 5/25: 100%|██████████| 10/10 [00:00<00:00, 25.31it/s, loss=7.25, acc=50]\n",
      "Training split 3 densenet121-pretrained-adam: 6/25: 100%|██████████| 5/5 [00:00<00:00,  6.34it/s, loss=2.63, acc=81.4] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 6/25: 100%|██████████| 10/10 [00:00<00:00, 25.77it/s, loss=5.94, acc=50] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 6/25: 100%|██████████| 10/10 [00:00<00:00, 24.87it/s, loss=7.39, acc=50]\n",
      "Training split 3 densenet121-pretrained-adam: 7/25: 100%|██████████| 5/5 [00:00<00:00,  6.13it/s, loss=2.56, acc=75.7] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 7/25: 100%|██████████| 10/10 [00:00<00:00, 27.62it/s, loss=5.72, acc=50] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 7/25: 100%|██████████| 10/10 [00:00<00:00, 24.33it/s, loss=7.38, acc=50]\n",
      "Training split 3 densenet121-pretrained-adam: 8/25: 100%|██████████| 5/5 [00:00<00:00,  6.08it/s, loss=2.25, acc=82.9] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 8/25: 100%|██████████| 10/10 [00:00<00:00, 27.17it/s, loss=5.74, acc=50] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 8/25: 100%|██████████| 10/10 [00:00<00:00, 25.50it/s, loss=7.28, acc=50]\n",
      "Training split 3 densenet121-pretrained-adam: 9/25: 100%|██████████| 5/5 [00:00<00:00,  6.08it/s, loss=2.34, acc=75.7] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 9/25: 100%|██████████| 10/10 [00:00<00:00, 25.06it/s, loss=5.8, acc=50]  \n",
      "Evaluating split 3 densenet121-pretrained-adam: 9/25: 100%|██████████| 10/10 [00:00<00:00, 24.87it/s, loss=7.23, acc=50]\n",
      "Training split 3 densenet121-pretrained-adam: 10/25: 100%|██████████| 5/5 [00:00<00:00,  5.57it/s, loss=1.87, acc=84.3] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 10/25: 100%|██████████| 10/10 [00:00<00:00, 28.73it/s, loss=6.25, acc=43.8]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 10/25: 100%|██████████| 10/10 [00:00<00:00, 27.54it/s, loss=7.19, acc=50]\n",
      "Training split 3 densenet121-pretrained-adam: 11/25: 100%|██████████| 5/5 [00:00<00:00,  5.64it/s, loss=2.29, acc=81.4] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 11/25: 100%|██████████| 10/10 [00:00<00:00, 28.16it/s, loss=6.38, acc=43.8]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 11/25: 100%|██████████| 10/10 [00:00<00:00, 24.50it/s, loss=7.23, acc=50]\n",
      "Training split 3 densenet121-pretrained-adam: 12/25: 100%|██████████| 5/5 [00:00<00:00,  6.09it/s, loss=1.83, acc=82.9]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 12/25: 100%|██████████| 10/10 [00:00<00:00, 27.93it/s, loss=6.26, acc=62.5]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 12/25: 100%|██████████| 10/10 [00:00<00:00, 24.50it/s, loss=7.1, acc=60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val 62.5, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training split 3 densenet121-pretrained-adam: 13/25: 100%|██████████| 5/5 [00:00<00:00,  5.83it/s, loss=1.45, acc=90]   \n",
      "Evaluating split 3 densenet121-pretrained-adam: 13/25: 100%|██████████| 10/10 [00:00<00:00, 27.17it/s, loss=6.62, acc=37.5]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 13/25: 100%|██████████| 10/10 [00:00<00:00, 26.51it/s, loss=6.92, acc=60]\n",
      "Training split 3 densenet121-pretrained-adam: 14/25: 100%|██████████| 5/5 [00:00<00:00,  5.62it/s, loss=1.35, acc=92.9] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 14/25: 100%|██████████| 10/10 [00:00<00:00, 26.80it/s, loss=6.81, acc=31.2]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 14/25: 100%|██████████| 10/10 [00:00<00:00, 26.91it/s, loss=7.16, acc=50]\n",
      "Training split 3 densenet121-pretrained-adam: 15/25: 100%|██████████| 5/5 [00:00<00:00,  5.67it/s, loss=1.65, acc=88.6] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 15/25: 100%|██████████| 10/10 [00:00<00:00, 26.80it/s, loss=7.2, acc=43.8]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 15/25: 100%|██████████| 10/10 [00:00<00:00, 28.23it/s, loss=7.01, acc=70]\n",
      "Training split 3 densenet121-pretrained-adam: 16/25: 100%|██████████| 5/5 [00:00<00:00,  6.16it/s, loss=1.37, acc=88.6] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 16/25: 100%|██████████| 10/10 [00:00<00:00, 26.73it/s, loss=6.66, acc=56.2]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 16/25: 100%|██████████| 10/10 [00:00<00:00, 28.08it/s, loss=7, acc=70]  \n",
      "Training split 3 densenet121-pretrained-adam: 17/25: 100%|██████████| 5/5 [00:00<00:00,  5.16it/s, loss=1.36, acc=94.3] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 17/25: 100%|██████████| 10/10 [00:00<00:00, 27.62it/s, loss=6.42, acc=56.2]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 17/25: 100%|██████████| 10/10 [00:00<00:00, 26.04it/s, loss=6.91, acc=70]\n",
      "Training split 3 densenet121-pretrained-adam: 18/25: 100%|██████████| 5/5 [00:00<00:00,  5.83it/s, loss=1.34, acc=91.4] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 18/25: 100%|██████████| 10/10 [00:00<00:00, 28.24it/s, loss=6.61, acc=56.2]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 18/25: 100%|██████████| 10/10 [00:00<00:00, 27.09it/s, loss=7.34, acc=70]\n",
      "Training split 3 densenet121-pretrained-adam: 19/25: 100%|██████████| 5/5 [00:00<00:00,  5.44it/s, loss=1.24, acc=92.9] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 19/25: 100%|██████████| 10/10 [00:00<00:00, 24.99it/s, loss=6.38, acc=31.2]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 19/25: 100%|██████████| 10/10 [00:00<00:00, 28.32it/s, loss=7.37, acc=50]\n",
      "Training split 3 densenet121-pretrained-adam: 20/25: 100%|██████████| 5/5 [00:00<00:00,  5.85it/s, loss=1.19, acc=91.4] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 20/25: 100%|██████████| 10/10 [00:00<00:00, 27.17it/s, loss=6.5, acc=31.2]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 20/25: 100%|██████████| 10/10 [00:00<00:00, 26.45it/s, loss=7.57, acc=50]\n",
      "Training split 3 densenet121-pretrained-adam: 21/25: 100%|██████████| 5/5 [00:00<00:00,  5.66it/s, loss=0.72, acc=95.7] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 21/25: 100%|██████████| 10/10 [00:00<00:00, 27.54it/s, loss=6.96, acc=43.8]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 21/25: 100%|██████████| 10/10 [00:00<00:00, 27.77it/s, loss=6.87, acc=60]\n",
      "Training split 3 densenet121-pretrained-adam: 22/25: 100%|██████████| 5/5 [00:00<00:00,  5.87it/s, loss=0.792, acc=94.3]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 22/25: 100%|██████████| 10/10 [00:00<00:00, 27.93it/s, loss=7.6, acc=43.8]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 22/25: 100%|██████████| 10/10 [00:00<00:00, 25.64it/s, loss=6.4, acc=60]\n",
      "Training split 3 densenet121-pretrained-adam: 23/25: 100%|██████████| 5/5 [00:00<00:00,  5.52it/s, loss=0.449, acc=100] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 23/25: 100%|██████████| 10/10 [00:00<00:00, 28.98it/s, loss=7.67, acc=50] \n",
      "Evaluating split 3 densenet121-pretrained-adam: 23/25: 100%|██████████| 10/10 [00:00<00:00, 27.32it/s, loss=6.22, acc=70]\n",
      "Training split 3 densenet121-pretrained-adam: 24/25: 100%|██████████| 5/5 [00:00<00:00,  6.34it/s, loss=0.699, acc=97.1]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 24/25: 100%|██████████| 10/10 [00:00<00:00, 26.04it/s, loss=7.13, acc=43.8]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 24/25: 100%|██████████| 10/10 [00:00<00:00, 26.04it/s, loss=6.59, acc=60]\n",
      "Training split 3 densenet121-pretrained-adam: 25/25: 100%|██████████| 5/5 [00:00<00:00,  5.97it/s, loss=0.721, acc=97.1]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 25/25: 100%|██████████| 10/10 [00:00<00:00, 26.24it/s, loss=7.12, acc=43.8]\n",
      "Evaluating split 3 densenet121-pretrained-adam: 25/25: 100%|██████████| 10/10 [00:00<00:00, 27.93it/s, loss=6.9, acc=60]\n",
      "Training split 4 densenet121-pretrained-adam: 1/25: 100%|██████████| 5/5 [00:00<00:00,  6.33it/s, loss=3.61, acc=48.6]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 1/25: 100%|██████████| 10/10 [00:00<00:00, 27.24it/s, loss=7.3, acc=25]  \n",
      "Evaluating split 4 densenet121-pretrained-adam: 1/25: 100%|██████████| 10/10 [00:00<00:00, 25.18it/s, loss=6.86, acc=60]\n",
      "Training split 4 densenet121-pretrained-adam: 2/25: 100%|██████████| 5/5 [00:00<00:00,  6.24it/s, loss=3.02, acc=67.1]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 2/25: 100%|██████████| 10/10 [00:00<00:00, 27.24it/s, loss=7.13, acc=37.5]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 2/25: 100%|██████████| 10/10 [00:00<00:00, 24.99it/s, loss=6.8, acc=60]\n",
      "Training split 4 densenet121-pretrained-adam: 3/25: 100%|██████████| 5/5 [00:00<00:00,  5.48it/s, loss=2.89, acc=74.3]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 3/25: 100%|██████████| 10/10 [00:00<00:00, 25.12it/s, loss=6.84, acc=37.5]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 3/25: 100%|██████████| 10/10 [00:00<00:00, 25.18it/s, loss=6.65, acc=70]\n",
      "Training split 4 densenet121-pretrained-adam: 4/25: 100%|██████████| 5/5 [00:00<00:00,  5.43it/s, loss=2.62, acc=70]  \n",
      "Evaluating split 4 densenet121-pretrained-adam: 4/25: 100%|██████████| 10/10 [00:00<00:00, 25.50it/s, loss=6.81, acc=50] \n",
      "Evaluating split 4 densenet121-pretrained-adam: 4/25: 100%|██████████| 10/10 [00:00<00:00, 27.02it/s, loss=6.63, acc=50]\n",
      "Training split 4 densenet121-pretrained-adam: 5/25: 100%|██████████| 5/5 [00:00<00:00,  5.97it/s, loss=2.79, acc=77.1] \n",
      "Evaluating split 4 densenet121-pretrained-adam: 5/25: 100%|██████████| 10/10 [00:00<00:00, 28.56it/s, loss=7.18, acc=37.5]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 5/25: 100%|██████████| 10/10 [00:00<00:00, 25.70it/s, loss=6.82, acc=50]\n",
      "Training split 4 densenet121-pretrained-adam: 6/25: 100%|██████████| 5/5 [00:00<00:00,  6.21it/s, loss=2.38, acc=84.3]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 6/25: 100%|██████████| 10/10 [00:00<00:00, 25.70it/s, loss=7.67, acc=37.5]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 6/25: 100%|██████████| 10/10 [00:00<00:00, 26.45it/s, loss=6.72, acc=40]\n",
      "Training split 4 densenet121-pretrained-adam: 7/25: 100%|██████████| 5/5 [00:00<00:00,  6.07it/s, loss=2.37, acc=82.9] \n",
      "Evaluating split 4 densenet121-pretrained-adam: 7/25: 100%|██████████| 10/10 [00:00<00:00, 27.62it/s, loss=7.86, acc=37.5]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 7/25: 100%|██████████| 10/10 [00:00<00:00, 28.24it/s, loss=6.95, acc=50]\n",
      "Training split 4 densenet121-pretrained-adam: 8/25: 100%|██████████| 5/5 [00:00<00:00,  5.93it/s, loss=2.05, acc=82.9] \n",
      "Evaluating split 4 densenet121-pretrained-adam: 8/25: 100%|██████████| 10/10 [00:00<00:00, 26.31it/s, loss=7.47, acc=31.2]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 8/25: 100%|██████████| 10/10 [00:00<00:00, 24.87it/s, loss=7.12, acc=50]\n",
      "Training split 4 densenet121-pretrained-adam: 9/25: 100%|██████████| 5/5 [00:00<00:00,  5.76it/s, loss=1.69, acc=90]   \n",
      "Evaluating split 4 densenet121-pretrained-adam: 9/25: 100%|██████████| 10/10 [00:00<00:00, 27.24it/s, loss=7.01, acc=37.5]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 9/25: 100%|██████████| 10/10 [00:00<00:00, 27.93it/s, loss=7.16, acc=40]\n",
      "Training split 4 densenet121-pretrained-adam: 10/25: 100%|██████████| 5/5 [00:00<00:00,  6.12it/s, loss=1.54, acc=87.1] \n",
      "Evaluating split 4 densenet121-pretrained-adam: 10/25: 100%|██████████| 10/10 [00:00<00:00, 25.44it/s, loss=6.63, acc=37.5]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 10/25: 100%|██████████| 10/10 [00:00<00:00, 27.17it/s, loss=7.17, acc=40]\n",
      "Training split 4 densenet121-pretrained-adam: 11/25: 100%|██████████| 5/5 [00:00<00:00,  5.71it/s, loss=1.86, acc=84.3] \n",
      "Evaluating split 4 densenet121-pretrained-adam: 11/25: 100%|██████████| 10/10 [00:00<00:00, 24.75it/s, loss=6.42, acc=37.5]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 11/25: 100%|██████████| 10/10 [00:00<00:00, 28.65it/s, loss=7.48, acc=40]\n",
      "Training split 4 densenet121-pretrained-adam: 12/25: 100%|██████████| 5/5 [00:00<00:00,  6.30it/s, loss=1.42, acc=92.9] \n",
      "Evaluating split 4 densenet121-pretrained-adam: 12/25: 100%|██████████| 10/10 [00:00<00:00, 28.81it/s, loss=6.25, acc=62.5]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 12/25: 100%|██████████| 10/10 [00:00<00:00, 26.31it/s, loss=7.36, acc=50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val 62.5, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training split 4 densenet121-pretrained-adam: 13/25: 100%|██████████| 5/5 [00:00<00:00,  5.87it/s, loss=1.46, acc=94.3] \n",
      "Evaluating split 4 densenet121-pretrained-adam: 13/25: 100%|██████████| 10/10 [00:00<00:00, 27.47it/s, loss=6.13, acc=68.8]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 13/25: 100%|██████████| 10/10 [00:00<00:00, 27.32it/s, loss=7.53, acc=60]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val 68.75, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training split 4 densenet121-pretrained-adam: 14/25: 100%|██████████| 5/5 [00:00<00:00,  5.80it/s, loss=1.94, acc=84.3] \n",
      "Evaluating split 4 densenet121-pretrained-adam: 14/25: 100%|██████████| 10/10 [00:00<00:00, 24.15it/s, loss=7.56, acc=56.2]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 14/25: 100%|██████████| 10/10 [00:00<00:00, 26.31it/s, loss=7.44, acc=60]\n",
      "Training split 4 densenet121-pretrained-adam: 15/25: 100%|██████████| 5/5 [00:00<00:00,  5.65it/s, loss=1.37, acc=87.1] \n",
      "Evaluating split 4 densenet121-pretrained-adam: 15/25: 100%|██████████| 10/10 [00:00<00:00, 26.95it/s, loss=8.24, acc=31.2]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 15/25: 100%|██████████| 10/10 [00:00<00:00, 25.77it/s, loss=7.39, acc=50]\n",
      "Training split 4 densenet121-pretrained-adam: 16/25: 100%|██████████| 5/5 [00:00<00:00,  6.19it/s, loss=1.42, acc=90]   \n",
      "Evaluating split 4 densenet121-pretrained-adam: 16/25: 100%|██████████| 10/10 [00:00<00:00, 29.23it/s, loss=8.75, acc=43.8]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 16/25: 100%|██████████| 10/10 [00:00<00:00, 26.52it/s, loss=7.11, acc=40]\n",
      "Training split 4 densenet121-pretrained-adam: 17/25: 100%|██████████| 5/5 [00:00<00:00,  6.16it/s, loss=1.19, acc=91.4] \n",
      "Evaluating split 4 densenet121-pretrained-adam: 17/25: 100%|██████████| 10/10 [00:00<00:00, 25.12it/s, loss=7.58, acc=50] \n",
      "Evaluating split 4 densenet121-pretrained-adam: 17/25: 100%|██████████| 10/10 [00:00<00:00, 25.12it/s, loss=6.89, acc=60]\n",
      "Training split 4 densenet121-pretrained-adam: 18/25: 100%|██████████| 5/5 [00:00<00:00,  5.94it/s, loss=1.52, acc=90]   \n",
      "Evaluating split 4 densenet121-pretrained-adam: 18/25: 100%|██████████| 10/10 [00:00<00:00, 24.38it/s, loss=6.88, acc=31.2]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 18/25: 100%|██████████| 10/10 [00:00<00:00, 27.24it/s, loss=6.45, acc=80]\n",
      "Training split 4 densenet121-pretrained-adam: 19/25: 100%|██████████| 5/5 [00:00<00:00,  5.48it/s, loss=0.741, acc=98.6]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 19/25: 100%|██████████| 10/10 [00:00<00:00, 26.04it/s, loss=7.01, acc=37.5]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 19/25: 100%|██████████| 10/10 [00:00<00:00, 26.88it/s, loss=6.46, acc=80]\n",
      "Training split 4 densenet121-pretrained-adam: 20/25: 100%|██████████| 5/5 [00:00<00:00,  5.28it/s, loss=0.853, acc=97.1]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 20/25: 100%|██████████| 10/10 [00:00<00:00, 27.85it/s, loss=6.74, acc=43.8]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 20/25: 100%|██████████| 10/10 [00:00<00:00, 26.45it/s, loss=6.78, acc=70]\n",
      "Training split 4 densenet121-pretrained-adam: 21/25: 100%|██████████| 5/5 [00:00<00:00,  6.40it/s, loss=0.596, acc=97.1]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 21/25: 100%|██████████| 10/10 [00:00<00:00, 28.00it/s, loss=6.9, acc=43.8]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 21/25: 100%|██████████| 10/10 [00:00<00:00, 27.54it/s, loss=7.28, acc=60]\n",
      "Training split 4 densenet121-pretrained-adam: 22/25: 100%|██████████| 5/5 [00:00<00:00,  5.67it/s, loss=0.614, acc=97.1]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 22/25: 100%|██████████| 10/10 [00:00<00:00, 25.64it/s, loss=6.3, acc=50]  \n",
      "Evaluating split 4 densenet121-pretrained-adam: 22/25: 100%|██████████| 10/10 [00:00<00:00, 27.69it/s, loss=7.41, acc=60]\n",
      "Training split 4 densenet121-pretrained-adam: 23/25: 100%|██████████| 5/5 [00:00<00:00,  5.61it/s, loss=1.02, acc=95.7] \n",
      "Evaluating split 4 densenet121-pretrained-adam: 23/25: 100%|██████████| 10/10 [00:00<00:00, 28.48it/s, loss=6.48, acc=50]  \n",
      "Evaluating split 4 densenet121-pretrained-adam: 23/25: 100%|██████████| 10/10 [00:00<00:00, 27.02it/s, loss=8.28, acc=60]\n",
      "Training split 4 densenet121-pretrained-adam: 24/25: 100%|██████████| 5/5 [00:00<00:00,  5.92it/s, loss=0.555, acc=98.6]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 24/25: 100%|██████████| 10/10 [00:00<00:00, 27.47it/s, loss=6.69, acc=50] \n",
      "Evaluating split 4 densenet121-pretrained-adam: 24/25: 100%|██████████| 10/10 [00:00<00:00, 27.54it/s, loss=9.06, acc=60]\n",
      "Training split 4 densenet121-pretrained-adam: 25/25: 100%|██████████| 5/5 [00:00<00:00,  5.11it/s, loss=1.18, acc=95.7] \n",
      "Evaluating split 4 densenet121-pretrained-adam: 25/25: 100%|██████████| 10/10 [00:00<00:00, 25.64it/s, loss=6.97, acc=43.8]\n",
      "Evaluating split 4 densenet121-pretrained-adam: 25/25: 100%|██████████| 10/10 [00:00<00:00, 26.17it/s, loss=9.18, acc=60]\n",
      "Training split 5 densenet121-pretrained-adam: 1/25: 100%|██████████| 5/5 [00:00<00:00,  6.13it/s, loss=3.61, acc=47.1] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 1/25: 100%|██████████| 10/10 [00:00<00:00, 26.95it/s, loss=6.01, acc=43.8]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 1/25: 100%|██████████| 10/10 [00:00<00:00, 24.26it/s, loss=7.17, acc=30]\n",
      "Training split 5 densenet121-pretrained-adam: 2/25: 100%|██████████| 5/5 [00:00<00:00,  6.21it/s, loss=3.21, acc=57.1] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 2/25: 100%|██████████| 10/10 [00:00<00:00, 25.97it/s, loss=5.79, acc=43.8]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 2/25: 100%|██████████| 10/10 [00:00<00:00, 27.32it/s, loss=7.37, acc=20]\n",
      "Training split 5 densenet121-pretrained-adam: 3/25: 100%|██████████| 5/5 [00:00<00:00,  5.94it/s, loss=2.77, acc=75.7] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 3/25: 100%|██████████| 10/10 [00:00<00:00, 26.59it/s, loss=5.81, acc=68.8]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 3/25: 100%|██████████| 10/10 [00:00<00:00, 25.97it/s, loss=7.3, acc=30]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val 68.75, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training split 5 densenet121-pretrained-adam: 4/25: 100%|██████████| 5/5 [00:00<00:00,  6.06it/s, loss=2.9, acc=78.6]  \n",
      "Evaluating split 5 densenet121-pretrained-adam: 4/25: 100%|██████████| 10/10 [00:00<00:00, 28.73it/s, loss=5.49, acc=68.8]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 4/25: 100%|██████████| 10/10 [00:00<00:00, 26.17it/s, loss=7.24, acc=40]\n",
      "Training split 5 densenet121-pretrained-adam: 5/25: 100%|██████████| 5/5 [00:00<00:00,  5.63it/s, loss=2.51, acc=80]  \n",
      "Evaluating split 5 densenet121-pretrained-adam: 5/25: 100%|██████████| 10/10 [00:00<00:00, 26.66it/s, loss=5.37, acc=50] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 5/25: 100%|██████████| 10/10 [00:00<00:00, 24.03it/s, loss=7.53, acc=50]\n",
      "Training split 5 densenet121-pretrained-adam: 6/25: 100%|██████████| 5/5 [00:00<00:00,  6.04it/s, loss=2.4, acc=74.3]  \n",
      "Evaluating split 5 densenet121-pretrained-adam: 6/25: 100%|██████████| 10/10 [00:00<00:00, 25.97it/s, loss=5.62, acc=50] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 6/25: 100%|██████████| 10/10 [00:00<00:00, 27.85it/s, loss=7.27, acc=50]\n",
      "Training split 5 densenet121-pretrained-adam: 7/25: 100%|██████████| 5/5 [00:00<00:00,  5.30it/s, loss=2.08, acc=78.6] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 7/25: 100%|██████████| 10/10 [00:00<00:00, 27.24it/s, loss=6.38, acc=43.8]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 7/25: 100%|██████████| 10/10 [00:00<00:00, 26.04it/s, loss=7.11, acc=30]\n",
      "Training split 5 densenet121-pretrained-adam: 8/25: 100%|██████████| 5/5 [00:00<00:00,  6.18it/s, loss=1.83, acc=85.7] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 8/25: 100%|██████████| 10/10 [00:00<00:00, 25.25it/s, loss=6.72, acc=56.2]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 8/25: 100%|██████████| 10/10 [00:00<00:00, 26.88it/s, loss=6.65, acc=60]\n",
      "Training split 5 densenet121-pretrained-adam: 9/25: 100%|██████████| 5/5 [00:00<00:00,  5.89it/s, loss=2.25, acc=80]   \n",
      "Evaluating split 5 densenet121-pretrained-adam: 9/25: 100%|██████████| 10/10 [00:00<00:00, 28.24it/s, loss=6.91, acc=25] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 9/25: 100%|██████████| 10/10 [00:00<00:00, 23.04it/s, loss=6.55, acc=50]\n",
      "Training split 5 densenet121-pretrained-adam: 10/25: 100%|██████████| 5/5 [00:00<00:00,  5.14it/s, loss=1.76, acc=82.9] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 10/25: 100%|██████████| 10/10 [00:00<00:00, 26.73it/s, loss=6.31, acc=43.8]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 10/25: 100%|██████████| 10/10 [00:00<00:00, 28.81it/s, loss=6.81, acc=40]\n",
      "Training split 5 densenet121-pretrained-adam: 11/25: 100%|██████████| 5/5 [00:00<00:00,  6.23it/s, loss=1.97, acc=92.9] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 11/25: 100%|██████████| 10/10 [00:00<00:00, 28.40it/s, loss=6.05, acc=75] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 11/25: 100%|██████████| 10/10 [00:00<00:00, 26.31it/s, loss=7.01, acc=40]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val 75.0, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training split 5 densenet121-pretrained-adam: 12/25: 100%|██████████| 5/5 [00:00<00:00,  6.19it/s, loss=1.31, acc=95.7] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 12/25: 100%|██████████| 10/10 [00:00<00:00, 24.75it/s, loss=6, acc=75]    \n",
      "Evaluating split 5 densenet121-pretrained-adam: 12/25: 100%|██████████| 10/10 [00:00<00:00, 29.32it/s, loss=7.27, acc=50]\n",
      "Training split 5 densenet121-pretrained-adam: 13/25: 100%|██████████| 5/5 [00:00<00:00,  5.65it/s, loss=1.6, acc=87.1]  \n",
      "Evaluating split 5 densenet121-pretrained-adam: 13/25: 100%|██████████| 10/10 [00:00<00:00, 26.45it/s, loss=6.19, acc=75] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 13/25: 100%|██████████| 10/10 [00:00<00:00, 26.45it/s, loss=7.06, acc=30]\n",
      "Training split 5 densenet121-pretrained-adam: 14/25: 100%|██████████| 5/5 [00:00<00:00,  5.58it/s, loss=0.914, acc=91.4]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 14/25: 100%|██████████| 10/10 [00:00<00:00, 26.80it/s, loss=6.7, acc=37.5]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 14/25: 100%|██████████| 10/10 [00:00<00:00, 27.93it/s, loss=6.72, acc=40]\n",
      "Training split 5 densenet121-pretrained-adam: 15/25: 100%|██████████| 5/5 [00:00<00:00,  6.13it/s, loss=1.19, acc=90]   \n",
      "Evaluating split 5 densenet121-pretrained-adam: 15/25: 100%|██████████| 10/10 [00:00<00:00, 27.39it/s, loss=6.75, acc=37.5]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 15/25: 100%|██████████| 10/10 [00:00<00:00, 27.17it/s, loss=6.33, acc=60]\n",
      "Training split 5 densenet121-pretrained-adam: 16/25: 100%|██████████| 5/5 [00:00<00:00,  5.70it/s, loss=1.25, acc=85.7] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 16/25: 100%|██████████| 10/10 [00:00<00:00, 25.57it/s, loss=6.93, acc=37.5]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 16/25: 100%|██████████| 10/10 [00:00<00:00, 28.32it/s, loss=6.18, acc=50]\n",
      "Training split 5 densenet121-pretrained-adam: 17/25: 100%|██████████| 5/5 [00:00<00:00,  5.71it/s, loss=0.976, acc=94.3]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 17/25: 100%|██████████| 10/10 [00:00<00:00, 26.87it/s, loss=6.88, acc=50] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 17/25: 100%|██████████| 10/10 [00:00<00:00, 29.06it/s, loss=5.75, acc=60]\n",
      "Training split 5 densenet121-pretrained-adam: 18/25: 100%|██████████| 5/5 [00:00<00:00,  5.94it/s, loss=1.3, acc=85.7]  \n",
      "Evaluating split 5 densenet121-pretrained-adam: 18/25: 100%|██████████| 10/10 [00:00<00:00, 28.31it/s, loss=6.61, acc=37.5]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 18/25: 100%|██████████| 10/10 [00:00<00:00, 26.04it/s, loss=5.63, acc=60]\n",
      "Training split 5 densenet121-pretrained-adam: 19/25: 100%|██████████| 5/5 [00:00<00:00,  6.37it/s, loss=0.848, acc=98.6]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 19/25: 100%|██████████| 10/10 [00:00<00:00, 23.80it/s, loss=6.49, acc=37.5]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 19/25: 100%|██████████| 10/10 [00:00<00:00, 26.10it/s, loss=6.13, acc=60]\n",
      "Training split 5 densenet121-pretrained-adam: 20/25: 100%|██████████| 5/5 [00:00<00:00,  5.80it/s, loss=0.669, acc=98.6]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 20/25: 100%|██████████| 10/10 [00:00<00:00, 26.38it/s, loss=6.95, acc=37.5]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 20/25: 100%|██████████| 10/10 [00:00<00:00, 26.59it/s, loss=6.57, acc=50]\n",
      "Training split 5 densenet121-pretrained-adam: 21/25: 100%|██████████| 5/5 [00:00<00:00,  5.92it/s, loss=0.926, acc=95.7]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 21/25: 100%|██████████| 10/10 [00:00<00:00, 25.06it/s, loss=6.22, acc=50] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 21/25: 100%|██████████| 10/10 [00:00<00:00, 26.52it/s, loss=6.51, acc=60]\n",
      "Training split 5 densenet121-pretrained-adam: 22/25: 100%|██████████| 5/5 [00:00<00:00,  5.96it/s, loss=0.748, acc=98.6]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 22/25: 100%|██████████| 10/10 [00:00<00:00, 24.81it/s, loss=5.97, acc=50] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 22/25: 100%|██████████| 10/10 [00:00<00:00, 26.80it/s, loss=6.64, acc=60]\n",
      "Training split 5 densenet121-pretrained-adam: 23/25: 100%|██████████| 5/5 [00:00<00:00,  5.18it/s, loss=0.488, acc=98.6]\n",
      "Evaluating split 5 densenet121-pretrained-adam: 23/25: 100%|██████████| 10/10 [00:00<00:00, 25.64it/s, loss=6.35, acc=50] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 23/25: 100%|██████████| 10/10 [00:00<00:00, 28.01it/s, loss=6.44, acc=60]\n",
      "Training split 5 densenet121-pretrained-adam: 24/25: 100%|██████████| 5/5 [00:00<00:00,  5.74it/s, loss=0.375, acc=100] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 24/25: 100%|██████████| 10/10 [00:00<00:00, 28.16it/s, loss=5.97, acc=50] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 24/25: 100%|██████████| 10/10 [00:00<00:00, 27.09it/s, loss=6.07, acc=60]\n",
      "Training split 5 densenet121-pretrained-adam: 25/25: 100%|██████████| 5/5 [00:00<00:00,  6.30it/s, loss=1.78, acc=94.3] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 25/25: 100%|██████████| 10/10 [00:00<00:00, 25.31it/s, loss=6.27, acc=50] \n",
      "Evaluating split 5 densenet121-pretrained-adam: 25/25: 100%|██████████| 10/10 [00:00<00:00, 27.62it/s, loss=5.39, acc=70]\n",
      "Training split 6 densenet121-pretrained-adam: 1/25: 100%|██████████| 5/5 [00:00<00:00,  6.28it/s, loss=3.42, acc=52.9]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 1/25: 100%|██████████| 10/10 [00:00<00:00, 25.97it/s, loss=6.99, acc=31.2]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 1/25: 100%|██████████| 10/10 [00:00<00:00, 28.73it/s, loss=7.48, acc=40]\n",
      "Training split 6 densenet121-pretrained-adam: 2/25: 100%|██████████| 5/5 [00:00<00:00,  5.57it/s, loss=3.2, acc=70]   \n",
      "Evaluating split 6 densenet121-pretrained-adam: 2/25: 100%|██████████| 10/10 [00:00<00:00, 25.64it/s, loss=6.79, acc=43.8]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 2/25: 100%|██████████| 10/10 [00:00<00:00, 28.08it/s, loss=7.41, acc=50]\n",
      "Training split 6 densenet121-pretrained-adam: 3/25: 100%|██████████| 5/5 [00:00<00:00,  5.85it/s, loss=2.86, acc=71.4]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 3/25: 100%|██████████| 10/10 [00:00<00:00, 27.24it/s, loss=6.17, acc=50] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 3/25: 100%|██████████| 10/10 [00:00<00:00, 28.08it/s, loss=7.54, acc=50]\n",
      "Training split 6 densenet121-pretrained-adam: 4/25: 100%|██████████| 5/5 [00:00<00:00,  5.31it/s, loss=2.42, acc=80]   \n",
      "Evaluating split 6 densenet121-pretrained-adam: 4/25: 100%|██████████| 10/10 [00:00<00:00, 24.59it/s, loss=5.66, acc=50] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 4/25: 100%|██████████| 10/10 [00:00<00:00, 26.66it/s, loss=7.83, acc=50]\n",
      "Training split 6 densenet121-pretrained-adam: 5/25: 100%|██████████| 5/5 [00:00<00:00,  5.68it/s, loss=2.56, acc=75.7] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 5/25: 100%|██████████| 10/10 [00:00<00:00, 24.56it/s, loss=5.7, acc=50]  \n",
      "Evaluating split 6 densenet121-pretrained-adam: 5/25: 100%|██████████| 10/10 [00:00<00:00, 26.17it/s, loss=7.79, acc=50]\n",
      "Training split 6 densenet121-pretrained-adam: 6/25: 100%|██████████| 5/5 [00:00<00:00,  5.46it/s, loss=2.45, acc=77.1]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 6/25: 100%|██████████| 10/10 [00:00<00:00, 28.81it/s, loss=5.77, acc=50] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 6/25: 100%|██████████| 10/10 [00:00<00:00, 24.81it/s, loss=7.5, acc=50]\n",
      "Training split 6 densenet121-pretrained-adam: 7/25: 100%|██████████| 5/5 [00:00<00:00,  5.73it/s, loss=2.21, acc=82.9] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 7/25: 100%|██████████| 10/10 [00:00<00:00, 24.93it/s, loss=5.94, acc=50] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 7/25: 100%|██████████| 10/10 [00:00<00:00, 23.86it/s, loss=6.89, acc=50]\n",
      "Training split 6 densenet121-pretrained-adam: 8/25: 100%|██████████| 5/5 [00:00<00:00,  5.38it/s, loss=2.07, acc=81.4] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 8/25: 100%|██████████| 10/10 [00:00<00:00, 27.39it/s, loss=6.35, acc=31.2]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 8/25: 100%|██████████| 10/10 [00:00<00:00, 25.37it/s, loss=6.78, acc=70]\n",
      "Training split 6 densenet121-pretrained-adam: 9/25: 100%|██████████| 5/5 [00:00<00:00,  5.54it/s, loss=2.12, acc=81.4] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 9/25: 100%|██████████| 10/10 [00:00<00:00, 26.10it/s, loss=6.83, acc=75] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 9/25: 100%|██████████| 10/10 [00:00<00:00, 25.97it/s, loss=6.6, acc=70]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val 75.0, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training split 6 densenet121-pretrained-adam: 10/25: 100%|██████████| 5/5 [00:00<00:00,  5.67it/s, loss=1.84, acc=84.3] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 10/25: 100%|██████████| 10/10 [00:00<00:00, 26.04it/s, loss=8.8, acc=50]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 10/25: 100%|██████████| 10/10 [00:00<00:00, 27.17it/s, loss=6.73, acc=50]\n",
      "Training split 6 densenet121-pretrained-adam: 11/25: 100%|██████████| 5/5 [00:00<00:00,  5.97it/s, loss=2.21, acc=80]   \n",
      "Evaluating split 6 densenet121-pretrained-adam: 11/25: 100%|██████████| 10/10 [00:00<00:00, 27.77it/s, loss=9.87, acc=50]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 11/25: 100%|██████████| 10/10 [00:00<00:00, 26.45it/s, loss=6.84, acc=40]\n",
      "Training split 6 densenet121-pretrained-adam: 12/25: 100%|██████████| 5/5 [00:00<00:00,  5.85it/s, loss=1.43, acc=91.4] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 12/25: 100%|██████████| 10/10 [00:00<00:00, 26.17it/s, loss=9.37, acc=56.2]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 12/25: 100%|██████████| 10/10 [00:00<00:00, 25.18it/s, loss=7.11, acc=40]\n",
      "Training split 6 densenet121-pretrained-adam: 13/25: 100%|██████████| 5/5 [00:00<00:00,  6.14it/s, loss=1.92, acc=80]   \n",
      "Evaluating split 6 densenet121-pretrained-adam: 13/25: 100%|██████████| 10/10 [00:00<00:00, 25.12it/s, loss=8.05, acc=43.8]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 13/25: 100%|██████████| 10/10 [00:00<00:00, 28.73it/s, loss=6.86, acc=40]\n",
      "Training split 6 densenet121-pretrained-adam: 14/25: 100%|██████████| 5/5 [00:00<00:00,  5.94it/s, loss=1.3, acc=91.4]  \n",
      "Evaluating split 6 densenet121-pretrained-adam: 14/25: 100%|██████████| 10/10 [00:00<00:00, 25.97it/s, loss=7.55, acc=68.8]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 14/25: 100%|██████████| 10/10 [00:00<00:00, 26.73it/s, loss=6.65, acc=60]\n",
      "Training split 6 densenet121-pretrained-adam: 15/25: 100%|██████████| 5/5 [00:00<00:00,  5.62it/s, loss=1.33, acc=92.9] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 15/25: 100%|██████████| 10/10 [00:00<00:00, 27.54it/s, loss=7.58, acc=68.8]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 15/25: 100%|██████████| 10/10 [00:00<00:00, 27.85it/s, loss=6.83, acc=40]\n",
      "Training split 6 densenet121-pretrained-adam: 16/25: 100%|██████████| 5/5 [00:00<00:00,  6.25it/s, loss=1.02, acc=95.7] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 16/25: 100%|██████████| 10/10 [00:00<00:00, 28.24it/s, loss=6.58, acc=75] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 16/25: 100%|██████████| 10/10 [00:00<00:00, 25.31it/s, loss=7, acc=40]  \n",
      "Training split 6 densenet121-pretrained-adam: 17/25: 100%|██████████| 5/5 [00:00<00:00,  5.35it/s, loss=1.23, acc=94.3] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 17/25: 100%|██████████| 10/10 [00:00<00:00, 27.85it/s, loss=6.4, acc=68.8]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 17/25: 100%|██████████| 10/10 [00:00<00:00, 27.09it/s, loss=7.09, acc=30]\n",
      "Training split 6 densenet121-pretrained-adam: 18/25: 100%|██████████| 5/5 [00:00<00:00,  6.48it/s, loss=0.941, acc=95.7]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 18/25: 100%|██████████| 10/10 [00:00<00:00, 28.65it/s, loss=6.68, acc=68.8]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 18/25: 100%|██████████| 10/10 [00:00<00:00, 24.93it/s, loss=7.08, acc=50]\n",
      "Training split 6 densenet121-pretrained-adam: 19/25: 100%|██████████| 5/5 [00:00<00:00,  5.83it/s, loss=0.918, acc=95.7]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 19/25: 100%|██████████| 10/10 [00:00<00:00, 26.31it/s, loss=6.43, acc=56.2]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 19/25: 100%|██████████| 10/10 [00:00<00:00, 25.57it/s, loss=7.07, acc=40]\n",
      "Training split 6 densenet121-pretrained-adam: 20/25: 100%|██████████| 5/5 [00:00<00:00,  5.71it/s, loss=1.05, acc=92.9] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 20/25: 100%|██████████| 10/10 [00:00<00:00, 26.66it/s, loss=7.29, acc=50] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 20/25: 100%|██████████| 10/10 [00:00<00:00, 24.62it/s, loss=6.86, acc=60]\n",
      "Training split 6 densenet121-pretrained-adam: 21/25: 100%|██████████| 5/5 [00:00<00:00,  5.35it/s, loss=0.855, acc=94.3]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 21/25: 100%|██████████| 10/10 [00:00<00:00, 25.25it/s, loss=6.22, acc=62.5]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 21/25: 100%|██████████| 10/10 [00:00<00:00, 24.63it/s, loss=7.17, acc=50]\n",
      "Training split 6 densenet121-pretrained-adam: 22/25: 100%|██████████| 5/5 [00:00<00:00,  5.76it/s, loss=0.539, acc=98.6]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 22/25: 100%|██████████| 10/10 [00:00<00:00, 26.45it/s, loss=5.54, acc=50] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 22/25: 100%|██████████| 10/10 [00:00<00:00, 25.57it/s, loss=7.54, acc=60]\n",
      "Training split 6 densenet121-pretrained-adam: 23/25: 100%|██████████| 5/5 [00:00<00:00,  5.41it/s, loss=0.71, acc=97.1] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 23/25: 100%|██████████| 10/10 [00:00<00:00, 27.39it/s, loss=4.97, acc=50] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 23/25: 100%|██████████| 10/10 [00:00<00:00, 26.80it/s, loss=7.1, acc=60]\n",
      "Training split 6 densenet121-pretrained-adam: 24/25: 100%|██████████| 5/5 [00:00<00:00,  5.91it/s, loss=0.636, acc=95.7]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 24/25: 100%|██████████| 10/10 [00:00<00:00, 25.50it/s, loss=6.39, acc=50] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 24/25: 100%|██████████| 10/10 [00:00<00:00, 26.45it/s, loss=6.86, acc=60]\n",
      "Training split 6 densenet121-pretrained-adam: 25/25: 100%|██████████| 5/5 [00:00<00:00,  5.85it/s, loss=1.06, acc=92.9] \n",
      "Evaluating split 6 densenet121-pretrained-adam: 25/25: 100%|██████████| 10/10 [00:00<00:00, 25.64it/s, loss=5.21, acc=56.2]\n",
      "Evaluating split 6 densenet121-pretrained-adam: 25/25: 100%|██████████| 10/10 [00:00<00:00, 25.31it/s, loss=7.01, acc=60]\n",
      "Training split 7 densenet121-pretrained-adam: 1/25: 100%|██████████| 5/5 [00:00<00:00,  5.88it/s, loss=3.55, acc=51.4] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 1/25: 100%|██████████| 10/10 [00:00<00:00, 25.50it/s, loss=7.34, acc=37.5]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 1/25: 100%|██████████| 10/10 [00:00<00:00, 25.90it/s, loss=6.68, acc=60]\n",
      "Training split 7 densenet121-pretrained-adam: 2/25: 100%|██████████| 5/5 [00:00<00:00,  5.81it/s, loss=3.37, acc=64.3]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 2/25: 100%|██████████| 10/10 [00:00<00:00, 25.97it/s, loss=7.07, acc=25] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 2/25: 100%|██████████| 10/10 [00:00<00:00, 26.17it/s, loss=6.66, acc=60]\n",
      "Training split 7 densenet121-pretrained-adam: 3/25: 100%|██████████| 5/5 [00:00<00:00,  5.27it/s, loss=3.18, acc=60]  \n",
      "Evaluating split 7 densenet121-pretrained-adam: 3/25: 100%|██████████| 10/10 [00:00<00:00, 26.80it/s, loss=7.06, acc=25] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 3/25: 100%|██████████| 10/10 [00:00<00:00, 26.04it/s, loss=6.71, acc=60]\n",
      "Training split 7 densenet121-pretrained-adam: 4/25: 100%|██████████| 5/5 [00:00<00:00,  5.82it/s, loss=2.56, acc=72.9]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 4/25: 100%|██████████| 10/10 [00:00<00:00, 25.83it/s, loss=6.93, acc=31.2]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 4/25: 100%|██████████| 10/10 [00:00<00:00, 27.77it/s, loss=6.97, acc=40]\n",
      "Training split 7 densenet121-pretrained-adam: 5/25: 100%|██████████| 5/5 [00:00<00:00,  5.95it/s, loss=2.72, acc=67.1]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 5/25: 100%|██████████| 10/10 [00:00<00:00, 27.77it/s, loss=6.84, acc=25] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 5/25: 100%|██████████| 10/10 [00:00<00:00, 27.17it/s, loss=6.83, acc=50]\n",
      "Training split 7 densenet121-pretrained-adam: 6/25: 100%|██████████| 5/5 [00:00<00:00,  5.36it/s, loss=2.42, acc=77.1] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 6/25: 100%|██████████| 10/10 [00:00<00:00, 26.17it/s, loss=6.48, acc=37.5]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 6/25: 100%|██████████| 10/10 [00:00<00:00, 24.33it/s, loss=6.85, acc=50]\n",
      "Training split 7 densenet121-pretrained-adam: 7/25: 100%|██████████| 5/5 [00:00<00:00,  5.48it/s, loss=2.14, acc=78.6] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 7/25: 100%|██████████| 10/10 [00:00<00:00, 27.32it/s, loss=6.24, acc=43.8]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 7/25: 100%|██████████| 10/10 [00:00<00:00, 27.85it/s, loss=6.69, acc=50]\n",
      "Training split 7 densenet121-pretrained-adam: 8/25: 100%|██████████| 5/5 [00:00<00:00,  5.81it/s, loss=2.43, acc=81.4] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 8/25: 100%|██████████| 10/10 [00:00<00:00, 27.62it/s, loss=6.35, acc=37.5]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 8/25: 100%|██████████| 10/10 [00:00<00:00, 25.37it/s, loss=6.71, acc=50]\n",
      "Training split 7 densenet121-pretrained-adam: 9/25: 100%|██████████| 5/5 [00:00<00:00,  5.88it/s, loss=1.67, acc=91.4] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 9/25: 100%|██████████| 10/10 [00:00<00:00, 24.09it/s, loss=6.14, acc=43.8]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 9/25: 100%|██████████| 10/10 [00:00<00:00, 24.69it/s, loss=7.1, acc=50]\n",
      "Training split 7 densenet121-pretrained-adam: 10/25: 100%|██████████| 5/5 [00:00<00:00,  5.62it/s, loss=2.04, acc=85.7] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 10/25: 100%|██████████| 10/10 [00:00<00:00, 26.88it/s, loss=6.16, acc=43.8]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 10/25: 100%|██████████| 10/10 [00:00<00:00, 26.73it/s, loss=7.31, acc=60]\n",
      "Training split 7 densenet121-pretrained-adam: 11/25: 100%|██████████| 5/5 [00:00<00:00,  5.84it/s, loss=1.7, acc=87.1]  \n",
      "Evaluating split 7 densenet121-pretrained-adam: 11/25: 100%|██████████| 10/10 [00:00<00:00, 26.45it/s, loss=6.36, acc=43.8]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 11/25: 100%|██████████| 10/10 [00:00<00:00, 26.59it/s, loss=7.34, acc=60]\n",
      "Training split 7 densenet121-pretrained-adam: 12/25: 100%|██████████| 5/5 [00:00<00:00,  5.41it/s, loss=1.49, acc=88.6] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 12/25: 100%|██████████| 10/10 [00:00<00:00, 25.12it/s, loss=6.44, acc=43.8]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 12/25: 100%|██████████| 10/10 [00:00<00:00, 25.37it/s, loss=7.4, acc=60]\n",
      "Training split 7 densenet121-pretrained-adam: 13/25: 100%|██████████| 5/5 [00:00<00:00,  6.00it/s, loss=1.85, acc=84.3] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 13/25: 100%|██████████| 10/10 [00:00<00:00, 25.83it/s, loss=6.83, acc=37.5]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 13/25: 100%|██████████| 10/10 [00:00<00:00, 27.17it/s, loss=7.11, acc=60]\n",
      "Training split 7 densenet121-pretrained-adam: 14/25: 100%|██████████| 5/5 [00:00<00:00,  5.96it/s, loss=1.54, acc=92.9] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 14/25: 100%|██████████| 10/10 [00:00<00:00, 27.39it/s, loss=6.94, acc=43.8]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 14/25: 100%|██████████| 10/10 [00:00<00:00, 25.25it/s, loss=6.83, acc=60]\n",
      "Training split 7 densenet121-pretrained-adam: 15/25: 100%|██████████| 5/5 [00:00<00:00,  6.02it/s, loss=1.14, acc=97.1] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 15/25: 100%|██████████| 10/10 [00:00<00:00, 27.32it/s, loss=6.84, acc=37.5]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 15/25: 100%|██████████| 10/10 [00:00<00:00, 25.90it/s, loss=7.1, acc=60]\n",
      "Training split 7 densenet121-pretrained-adam: 16/25: 100%|██████████| 5/5 [00:00<00:00,  6.15it/s, loss=1.18, acc=92.9] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 16/25: 100%|██████████| 10/10 [00:00<00:00, 27.24it/s, loss=6.85, acc=50] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 16/25: 100%|██████████| 10/10 [00:00<00:00, 26.66it/s, loss=7.42, acc=60]\n",
      "Training split 7 densenet121-pretrained-adam: 17/25: 100%|██████████| 5/5 [00:00<00:00,  5.54it/s, loss=1.07, acc=92.9] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 17/25: 100%|██████████| 10/10 [00:00<00:00, 27.32it/s, loss=7.41, acc=31.2]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 17/25: 100%|██████████| 10/10 [00:00<00:00, 25.77it/s, loss=7.25, acc=60]\n",
      "Training split 7 densenet121-pretrained-adam: 18/25: 100%|██████████| 5/5 [00:00<00:00,  5.89it/s, loss=1.01, acc=95.7] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 18/25: 100%|██████████| 10/10 [00:00<00:00, 27.09it/s, loss=7.46, acc=37.5]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 18/25: 100%|██████████| 10/10 [00:00<00:00, 24.15it/s, loss=7.45, acc=60]\n",
      "Training split 7 densenet121-pretrained-adam: 19/25: 100%|██████████| 5/5 [00:00<00:00,  5.76it/s, loss=1.61, acc=85.7] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 19/25: 100%|██████████| 10/10 [00:00<00:00, 25.25it/s, loss=7.07, acc=37.5]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 19/25: 100%|██████████| 10/10 [00:00<00:00, 27.09it/s, loss=7.27, acc=60]\n",
      "Training split 7 densenet121-pretrained-adam: 20/25: 100%|██████████| 5/5 [00:00<00:00,  6.02it/s, loss=0.874, acc=97.1]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 20/25: 100%|██████████| 10/10 [00:00<00:00, 26.73it/s, loss=5.96, acc=50] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 20/25: 100%|██████████| 10/10 [00:00<00:00, 26.17it/s, loss=7.61, acc=60]\n",
      "Training split 7 densenet121-pretrained-adam: 21/25: 100%|██████████| 5/5 [00:00<00:00,  5.84it/s, loss=1.25, acc=88.6] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 21/25: 100%|██████████| 10/10 [00:00<00:00, 25.18it/s, loss=5.51, acc=50]  \n",
      "Evaluating split 7 densenet121-pretrained-adam: 21/25: 100%|██████████| 10/10 [00:00<00:00, 26.52it/s, loss=8.04, acc=60]\n",
      "Training split 7 densenet121-pretrained-adam: 22/25: 100%|██████████| 5/5 [00:00<00:00,  5.99it/s, loss=0.974, acc=95.7]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 22/25: 100%|██████████| 10/10 [00:00<00:00, 26.92it/s, loss=5.93, acc=50] \n",
      "Evaluating split 7 densenet121-pretrained-adam: 22/25: 100%|██████████| 10/10 [00:00<00:00, 25.50it/s, loss=8.17, acc=60]\n",
      "Training split 7 densenet121-pretrained-adam: 23/25: 100%|██████████| 5/5 [00:00<00:00,  6.03it/s, loss=0.681, acc=95.7]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 23/25: 100%|██████████| 10/10 [00:00<00:00, 26.59it/s, loss=6.47, acc=43.8]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 23/25: 100%|██████████| 10/10 [00:00<00:00, 24.21it/s, loss=8.66, acc=60]\n",
      "Training split 7 densenet121-pretrained-adam: 24/25: 100%|██████████| 5/5 [00:00<00:00,  6.32it/s, loss=0.881, acc=94.3]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 24/25: 100%|██████████| 10/10 [00:00<00:00, 26.04it/s, loss=6.48, acc=50]  \n",
      "Evaluating split 7 densenet121-pretrained-adam: 24/25: 100%|██████████| 10/10 [00:00<00:00, 25.18it/s, loss=9.19, acc=60]\n",
      "Training split 7 densenet121-pretrained-adam: 25/25: 100%|██████████| 5/5 [00:00<00:00,  6.30it/s, loss=0.384, acc=98.6]\n",
      "Evaluating split 7 densenet121-pretrained-adam: 25/25: 100%|██████████| 10/10 [00:00<00:00, 26.88it/s, loss=6.62, acc=50]  \n",
      "Evaluating split 7 densenet121-pretrained-adam: 25/25: 100%|██████████| 10/10 [00:00<00:00, 24.75it/s, loss=9.23, acc=60]\n"
     ]
    }
   ],
   "source": [
    "results = dict(\n",
    "    (\n",
    "        splits,\n",
    "        dict(\n",
    "            (metrics, list())\n",
    "            for metrics in [\n",
    "                \"train_acc\",\n",
    "                \"train_loss\",\n",
    "                \"val_acc\",\n",
    "                \"val_loss\",\n",
    "                \"test_acc\",\n",
    "                \"test_loss\",\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    for splits in range(8)\n",
    ")\n",
    "for split in range(len(cv_set[\"val\"])):\n",
    "    df_train = cv_set[\"train\"][split].reset_index(drop=True)\n",
    "    df_val = cv_set[\"val\"][split].reset_index(drop=True)\n",
    "    trainset = DopplerDataset(df_train, transform=transform[\"train\"])\n",
    "    valset = DopplerDataset(df_val, transform=transform[\"test\"])\n",
    "    model_name = \"densenet121-pretrained-adam\"\n",
    "    model = get_model(model_name).to(DEVICE)\n",
    "    lr = 1e-4\n",
    "    n_epoch = 25\n",
    "    bs = 16\n",
    "    # filename = f\"{model_name}-{lr}lr-{bs}bs-{n_epoch}e-split{split}-loss-weighted\"\n",
    "    filename = f\"{model_name}-{lr}lr-{bs}bs-{n_epoch}e-split{split}-loss-normal\"\n",
    "    train_counts = df_train[\"label\"].value_counts()\n",
    "    val_counts = df_val[\"label\"].value_counts()\n",
    "    class_weights = list(1 / train_counts)\n",
    "    sample_weights = [0] * len(df_train)\n",
    "    for idx, row in df_train.iterrows():\n",
    "        class_weight = class_weights[row[\"label\"]]\n",
    "        sample_weights[idx] = class_weight\n",
    "    sampler = WeightedRandomSampler(\n",
    "        sample_weights, num_samples=len(sample_weights), replacement=True\n",
    "    )\n",
    "    trainLoader = DataLoader(trainset, batch_size=bs, sampler=sampler)\n",
    "    valLoader = DataLoader(valset, batch_size=1, shuffle=False)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    # criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(train_counts[1]/train_counts[0]))\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    best_acc = 60.0\n",
    "    for epoch in range(n_epoch):\n",
    "        train_acc, train_loss = train(epoch, trainLoader, model, model_name, split)\n",
    "        val_acc, val_loss = evaluate_val(epoch, valLoader, model, model_name, split)\n",
    "        test_acc, test_loss = evaluate_test(epoch, testLoader, model, model_name, split)\n",
    "        results[split][\"train_acc\"].append(train_acc)\n",
    "        results[split][\"train_loss\"].append(train_loss)\n",
    "        results[split][\"val_acc\"].append(val_acc)\n",
    "        results[split][\"val_loss\"].append(val_loss)\n",
    "        results[split][\"test_acc\"].append(test_acc)\n",
    "        results[split][\"test_loss\"].append(test_loss)\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            print(f\"Best val {best_acc}, saving...\")\n",
    "            # torch.save(model, f\"../model/{filename}-{best_acc}val-{epoch}e.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "a_file = open(f\"../result_cv/{filename}.pkl\", \"wb\")\n",
    "pickle.dump(results, a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.88888888888889"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0-8, 1-2\n",
    "\n",
    "(7/9+0/1)/2*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "78529ff005b2955a7f084f720537a47ab243e8d5746d8af954335b872401c5bf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
